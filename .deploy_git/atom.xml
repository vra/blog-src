<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  
  <title><![CDATA[Yunfeng's Hexo Blog]]></title>
  <subtitle><![CDATA[Life is the process of learning]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://vra.github.io//"/>
  <updated>2017-01-08T09:24:11.570Z</updated>
  <id>http://vra.github.io//</id>
  
  <author>
    <name><![CDATA[Yunfeng Wang]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[summary-2016]]></title>
    <link href="http://vra.github.io/2017/01/08/summary-2016/"/>
    <id>http://vra.github.io/2017/01/08/summary-2016/</id>
    <published>2017-01-08T09:24:11.000Z</published>
    <updated>2017-01-08T09:24:11.570Z</updated>
    <content type="html"></content>
    <summary type="html">
    
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[关于英伟达显卡命名的姿势]]></title>
    <link href="http://vra.github.io/2016/12/18/nvidia-gpu-names/"/>
    <id>http://vra.github.io/2016/12/18/nvidia-gpu-names/</id>
    <published>2016-12-18T10:11:11.000Z</published>
    <updated>2017-01-08T09:23:44.658Z</updated>
    <content type="html"><![CDATA[<p>平时在实验中用到GPU的地方比较多，看新闻也总是能看到英伟达又出了什么型号的显卡等等，可是我一直没搞清楚该公司显卡名称的命名关系，今天特地查了下，总结在这里，以便以后翻阅。<br><a id="more"></a><br>Nvidia的GPU命名有4个层次：</p>
<ol>
<li>GPU 架构(microarchitecture), 表示GPU在芯片设计层面上的不同处理方式，包括的内容有计算单元(SIMD)的个数、有无L1,L2缓存、是否有双精度支持等。按时间顺序依次是Tesla, Fermi, Kepler， Maxwell, Pascal。</li>
<li>显卡系列：根据使用场景的不同，分成GeForce, Quadro, Tesla。GeForce用于家庭和个人电脑，包括游戏和娱乐等;Quadro用于工业渲染、艺术设计，工作站等场合。而Tesla用于科学计算，深度学习加速等场景。当然这三者的使用场景并没有严格的边界，想GeForce 系列的GTX 1080也可以用来做深度学习实验。</li>
<li>芯片型号，例如GT200、GK210、GM104、GF104， K80, M40等。其中第二个字母表示架构，如K40 中的K表示是Kepler架构,P100中的P表示Pascal架构。</li>
<li>针对GeForce系列，还有2系列，3系列，200系列，400系列等分类，像GeForce GTX 1080 就是10系列。</li>
</ol>
<p>需要注意的地方有：</p>
<ol>
<li>注意区分Tesla GPU架构和Tesla系列。前者已经用的不是很多了，而后者是最近才出的针对深度学习的系列，使用很多，像我们实验室用的K20,K80都是这个系列。</li>
<li>描述一个显卡的时候，一般是系列名+芯片型号，如 Tesla K80。 </li>
<li>针对GeForce系列，芯片型号一般是显卡型号+具体编号的形式，如 GeForce GT 705,其中GT 是显卡型号。</li>
<li>最近新出了一款 TiTan X, 主要要和GeForce GTX Tian X 区分。</li>
</ol>
<h2 id="参考：">参考：</h2><ol>
<li><a href="https://chenrudan.github.io/blog/2015/12/20/introductionofgpuhardware.html" target="_blank" rel="external">https://chenrudan.github.io/blog/2015/12/20/introductionofgpuhardware.html</a></li>
<li><a href="https://www.quora.com/What-is-NVIDIA-GPU-micro-architecture" target="_blank" rel="external">https://www.quora.com/What-is-NVIDIA-GPU-micro-architecture</a></li>
<li><a href="https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units" target="_blank" rel="external">https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>平时在实验中用到GPU的地方比较多，看新闻也总是能看到英伟达又出了什么型号的显卡等等，可是我一直没搞清楚该公司显卡名称的命名关系，今天特地查了下，总结在这里，以便以后翻阅。<br>]]>
    
    </summary>
    
      <category term="GPU" scheme="http://vra.github.io/tags/GPU/"/>
    
      <category term="Nvidia" scheme="http://vra.github.io/tags/Nvidia/"/>
    
      <category term="总结" scheme="http://vra.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Caffe中的Siamese网络]]></title>
    <link href="http://vra.github.io/2016/12/13/siamese-caffe/"/>
    <id>http://vra.github.io/2016/12/13/siamese-caffe/</id>
    <published>2016-12-13T13:05:01.000Z</published>
    <updated>2017-01-08T09:23:44.618Z</updated>
    <content type="html"><![CDATA[<p>Siamese原意是”泰国的,泰国人”,而与之相关的一个比较常见的词是”Siamese twin”, 意思是是”连体双胞胎”,所以Siamemse Network是从这个意思转变而来,指的是结构非常相似的两路网络,分别训练,<strong>但共享各个层的参数</strong>,在最后有一个连接的部分.Siamese网络对于相似性比较的场景比较有效.此外Siamese因为共享参数,所以能减少训练过程中的参数个数.<a href="http://vision.ia.ac.cn/zh/senimar/reports/Siamese-Network-Architecture-and-Applications-in-Computer-Vision.pdf" target="_blank" rel="external">这里</a>的slides讲解了Siamese网络在深度学习中的应用.这里我参照Caffe中的<a href="https://github.com/BVLC/caffe/tree/master/examples/siamese" target="_blank" rel="external">Siamese文档</a>, 以LeNet为例,简单地总结下Caffe中Siamese网络的prototxt文件的写法.<br><a id="more"></a></p>
<h3 id="1-_Data层">1. Data层</h3><p>Data层输入可以是LMDB和LevelDB格式的数据,这种格式的数据可以通过参照<code>$CAFFE_ROOT/examples/siamese/create_mnist_siamese.sh</code>来生成（该脚本是从MNIST原先的格式生成DB文件,如果要从JPEG格式的图片来生成DB文件,需要进行一定的修改）.<br>Data层有2个输出,一个是<code>pair_data</code>,表示配对好的图片对;另一个是<code>sim</code>,表示图片对是否属于同一个label.  </p>
<h3 id="2-_Slice层">2. Slice层</h3><p>Slice层是Caffe中的一个工具层,功能就是把输入的层(bottom)切分成几个输出层(top).官网给出的如下例子:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"slicer_label"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Slice"</span></span><br><span class="line">  bottom: <span class="string">"label"</span></span><br><span class="line">  <span class="comment">## Example of label with a shape N x 3 x 1 x 1</span></span><br><span class="line">  top: <span class="string">"label1"</span></span><br><span class="line">  top: <span class="string">"label2"</span></span><br><span class="line">  top: <span class="string">"label3"</span></span><br><span class="line">  slice_param &#123;</span><br><span class="line">    axis: <span class="number">1</span></span><br><span class="line">    slice_point: <span class="number">1</span></span><br><span class="line">    slice_point: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>完成的功能就是把slicer_label划分成3份.<code>axis</code>表示划分的维度,这里1表示在第二个维度上划分;<code>slice_point</code>表示划分的中间的点,分别是<code>1</code>,<code>2</code>表示在1-2层和2-3层之间进行一个划分.<br>在Siamese网络中,为了对数据对进行单独的训练,需要在Data层后面接一个Slice层,将数据均匀地划分为2个部分.  </p>
<h3 id="3-_共享层">3. 共享层</h3><p>后面的卷积层,Pooling层,Relu层对于两路网络是没有区别的,所以可以直接写好一路后,复制一份在后面作为另一路,不过得将name,bottom和top的名字改成不一样的(示例中第二路的名字都是在第一路对应层的名字后面加了个<code>_p</code>表示pair).  </p>
<h3 id="4-_如何共享参数">4. 如何共享参数</h3><p>两路网络如何共享参数呢？Caffe里是这样实现的:在每路中对应的层里面都定义一个同名的参数,这样更新参数的时候就可以共享参数了.如下面的例子:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">layer &#123;                                                                         </span><br><span class="line">  name: <span class="string">"ip2"</span>                                                                   </span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span>                                                          </span><br><span class="line">  bottom: <span class="string">"ip1"</span>                                                                 </span><br><span class="line">  top: <span class="string">"ip2"</span>                                                                    </span><br><span class="line">  param &#123;                                                                       </span><br><span class="line">    name: <span class="string">"ip2_w"</span>                                                               </span><br><span class="line">    lr_mult: <span class="number">1</span>                                                                  </span><br><span class="line">  &#125;                </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">layer &#123;                                                                         </span><br><span class="line">  name: <span class="string">"ip2_p"</span>                                                                 </span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span>                                                          </span><br><span class="line">  bottom: <span class="string">"ip1_p"</span>                                                               </span><br><span class="line">  top: <span class="string">"ip2_p"</span>                                                                  </span><br><span class="line">  param &#123;                                                                       </span><br><span class="line">    name: <span class="string">"ip2_w"</span>                                                               </span><br><span class="line">    lr_mult: <span class="number">1</span>                                                                  </span><br><span class="line">  &#125;              </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>上面例子中,两路网络对应层都定义了<code>ip2_w</code>的参数,这样训练的时候就可以共享这个变量的值了.  </p>
<h3 id="5-_feature层">5. feature层</h3><p>在2个全连接层后,我们将原来的分类的sofatmax层改为输出一个2维向量的全连接层:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;                                                                         </span><br><span class="line">  name: <span class="string">"feat"</span>                                                                  </span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span>                                                          </span><br><span class="line">  bottom: <span class="string">"ip2"</span>                                                                 </span><br><span class="line">  top: <span class="string">"feat"</span>                                                                   </span><br><span class="line">  param &#123;                                                                       </span><br><span class="line">    name: <span class="string">"feat_w"</span>                                                              </span><br><span class="line">    lr_mult: <span class="number">1</span>                                                                  </span><br><span class="line">  &#125;                                                                             </span><br><span class="line">  param &#123;                                                                       </span><br><span class="line">    name: <span class="string">"feat_b"</span>                                                              </span><br><span class="line">    lr_mult: <span class="number">2</span>                                                                  </span><br><span class="line">  &#125;                                                                             </span><br><span class="line">  inner_product_param &#123;                                                         </span><br><span class="line">    num_output: <span class="number">2</span>                                                               </span><br><span class="line">    weight_filler &#123;                                                             </span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span>                                                            </span><br><span class="line">    &#125;                                                                           </span><br><span class="line">    bias_filler &#123;                                                               </span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span>                                                          </span><br><span class="line">    &#125;                                                                           </span><br><span class="line">  &#125;                                                                             </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="6-_ContrastiveLoss层">6. ContrastiveLoss层</h3><p>在两个feature产生后,就可以利用2个feature和前面定义的<code>sim</code>来计算loss了.Siamese网络采用了一个叫做<a href="http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf" target="_blank" rel="external">“ContrastiveLoss”</a>的loss计算方式,如果两个图片越相似,则loss越小;如果越不相似,则loss越大.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;                                                                         </span><br><span class="line">  name: <span class="string">"loss"</span>                                                                  </span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ContrastiveLoss"</span>                                                       </span><br><span class="line">  bottom: <span class="string">"feat"</span>                                                                </span><br><span class="line">  bottom: <span class="string">"feat_p"</span>                                                              </span><br><span class="line">  bottom: <span class="string">"sim"</span>                                                                 </span><br><span class="line">  top: <span class="string">"loss"</span>                                                                   </span><br><span class="line">  contrastive_loss_param &#123;                                                      </span><br><span class="line">    margin: <span class="number">1</span>                                                                   </span><br><span class="line">  &#125;                                                                             </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="7-_网络结构的可视化">7. 网络结构的可视化</h3><p>上面就是所有的网络结构,利用<code>$CAFFE_ROOT/python/draw_net.py</code>这个脚本可以画出网络结构,如图所示:<br><img src="http://7xlt5t.com1.z0.glb.clouddn.com/prototxt.jpg" alt="Lenet的Siamese网络结构"></p>
<p>整个网络的完整内容如下:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br></pre></td><td class="code"><pre><span class="line">name: <span class="string">"mnist_siamese_train_test"</span></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pair_data"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Data"</span></span><br><span class="line">  top: <span class="string">"pair_data"</span></span><br><span class="line">  top: <span class="string">"sim"</span></span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TRAIN</span><br><span class="line">  &#125;</span><br><span class="line">  transform_param &#123;</span><br><span class="line">    scale: <span class="number">0.00390625</span></span><br><span class="line">  &#125;</span><br><span class="line">  data_param &#123;</span><br><span class="line">    <span class="built_in">source</span>: <span class="string">"examples/siamese/mnist_siamese_train_leveldb"</span></span><br><span class="line">    batch_size: <span class="number">64</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pair_data"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Data"</span></span><br><span class="line">  top: <span class="string">"pair_data"</span></span><br><span class="line">  top: <span class="string">"sim"</span></span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TEST</span><br><span class="line">  &#125;</span><br><span class="line">  transform_param &#123;</span><br><span class="line">    scale: <span class="number">0.00390625</span></span><br><span class="line">  &#125;</span><br><span class="line">  data_param &#123;</span><br><span class="line">    <span class="built_in">source</span>: <span class="string">"examples/siamese/mnist_siamese_test_leveldb"</span></span><br><span class="line">    batch_size: <span class="number">100</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"slice_pair"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Slice"</span></span><br><span class="line">  bottom: <span class="string">"pair_data"</span></span><br><span class="line">  top: <span class="string">"data"</span></span><br><span class="line">  top: <span class="string">"data_p"</span></span><br><span class="line">  slice_param &#123;</span><br><span class="line">    slice_dim: <span class="number">1</span></span><br><span class="line">    slice_point: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"data"</span></span><br><span class="line">  top: <span class="string">"conv1"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"conv1_w"</span></span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"conv1_b"</span></span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">20</span></span><br><span class="line">    kernel_size: <span class="number">5</span></span><br><span class="line">    stride: <span class="number">1</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"conv1"</span></span><br><span class="line">  top: <span class="string">"pool1"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: <span class="number">2</span></span><br><span class="line">    stride: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv2"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"pool1"</span></span><br><span class="line">  top: <span class="string">"conv2"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"conv2_w"</span></span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"conv2_b"</span></span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">50</span></span><br><span class="line">    kernel_size: <span class="number">5</span></span><br><span class="line">    stride: <span class="number">1</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool2"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"conv2"</span></span><br><span class="line">  top: <span class="string">"pool2"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: <span class="number">2</span></span><br><span class="line">    stride: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"ip1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"pool2"</span></span><br><span class="line">  top: <span class="string">"ip1"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"ip1_w"</span></span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"ip1_b"</span></span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: <span class="number">500</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"relu1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"ip1"</span></span><br><span class="line">  top: <span class="string">"ip1"</span></span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"ip2"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"ip1"</span></span><br><span class="line">  top: <span class="string">"ip2"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"ip2_w"</span></span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"ip2_b"</span></span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: <span class="number">10</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"feat"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"ip2"</span></span><br><span class="line">  top: <span class="string">"feat"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"feat_w"</span></span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"feat_b"</span></span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: <span class="number">2</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv1_p"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"data_p"</span></span><br><span class="line">  top: <span class="string">"conv1_p"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"conv1_w"</span></span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"conv1_b"</span></span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">20</span></span><br><span class="line">    kernel_size: <span class="number">5</span></span><br><span class="line">    stride: <span class="number">1</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool1_p"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"conv1_p"</span></span><br><span class="line">  top: <span class="string">"pool1_p"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: <span class="number">2</span></span><br><span class="line">    stride: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv2_p"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"pool1_p"</span></span><br><span class="line">  top: <span class="string">"conv2_p"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"conv2_w"</span></span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"conv2_b"</span></span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">50</span></span><br><span class="line">    kernel_size: <span class="number">5</span></span><br><span class="line">    stride: <span class="number">1</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool2_p"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"conv2_p"</span></span><br><span class="line">  top: <span class="string">"pool2_p"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: <span class="number">2</span></span><br><span class="line">    stride: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"ip1_p"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"pool2_p"</span></span><br><span class="line">  top: <span class="string">"ip1_p"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"ip1_w"</span></span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"ip1_b"</span></span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: <span class="number">500</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"relu1_p"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"ip1_p"</span></span><br><span class="line">  top: <span class="string">"ip1_p"</span></span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"ip2_p"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"ip1_p"</span></span><br><span class="line">  top: <span class="string">"ip2_p"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"ip2_w"</span></span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"ip2_b"</span></span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: <span class="number">10</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"feat_p"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"ip2_p"</span></span><br><span class="line">  top: <span class="string">"feat_p"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"feat_w"</span></span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    name: <span class="string">"feat_b"</span></span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: <span class="number">2</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"loss"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ContrastiveLoss"</span></span><br><span class="line">  bottom: <span class="string">"feat"</span></span><br><span class="line">  bottom: <span class="string">"feat_p"</span></span><br><span class="line">  bottom: <span class="string">"sim"</span></span><br><span class="line">  top: <span class="string">"loss"</span></span><br><span class="line">  contrastive_loss_param &#123;</span><br><span class="line">    margin: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="8-_训练过程">8. 训练过程</h3><p>训练过程与别的网络是一样的,这里就不具体展开了.</p>
<h3 id="9-_参考内容">9. 参考内容</h3><ol>
<li><a href="https://www.quora.com/What-are-Siamese-neural-networks-what-applications-are-they-good-for-and-why" target="_blank" rel="external">https://www.quora.com/What-are-Siamese-neural-networks-what-applications-are-they-good-for-and-why</a></li>
<li><a href="http://vision.ia.ac.cn/zh/senimar/reports/Siamese-Network-Architecture-and-Applications-in-Computer-Vision.pdf" target="_blank" rel="external">http://vision.ia.ac.cn/zh/senimar/reports/Siamese-Network-Architecture-and-Applications-in-Computer-Vision.pdf</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>Siamese原意是”泰国的,泰国人”,而与之相关的一个比较常见的词是”Siamese twin”, 意思是是”连体双胞胎”,所以Siamemse Network是从这个意思转变而来,指的是结构非常相似的两路网络,分别训练,<strong>但共享各个层的参数</strong>,在最后有一个连接的部分.Siamese网络对于相似性比较的场景比较有效.此外Siamese因为共享参数,所以能减少训练过程中的参数个数.<a href="http://vision.ia.ac.cn/zh/senimar/reports/Siamese-Network-Architecture-and-Applications-in-Computer-Vision.pdf">这里</a>的slides讲解了Siamese网络在深度学习中的应用.这里我参照Caffe中的<a href="https://github.com/BVLC/caffe/tree/master/examples/siamese">Siamese文档</a>, 以LeNet为例,简单地总结下Caffe中Siamese网络的prototxt文件的写法.<br>]]>
    
    </summary>
    
      <category term="Caffe" scheme="http://vra.github.io/tags/Caffe/"/>
    
      <category term="Siamese Network" scheme="http://vra.github.io/tags/Siamese-Network/"/>
    
      <category term="深度学习" scheme="http://vra.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[在Hexo博客里面插入asciinema终端记录视频]]></title>
    <link href="http://vra.github.io/2016/11/14/test-asciinema/"/>
    <id>http://vra.github.io/2016/11/14/test-asciinema/</id>
    <published>2016-11-14T07:33:47.000Z</published>
    <updated>2017-01-08T09:23:44.546Z</updated>
    <content type="html"><![CDATA[<h2 id="概述">概述</h2><p>前几天发现了一个很有意思的记录终端操作的工具<a href="https://asciinema.org/" target="_blank" rel="external">asciinema</a>,使用起来异常简单功能却很强大，很佩服开发者的想象力和创造力。<br>今天我在想，能否在Hexo博客里面插入asciinema录的视频呢？Google了一下，发现真的已经有人做出了该功能的插件<a href="https://github.com/narongdejsrn/hexo-tag-asciinema" target="_blank" rel="external">hexo-tag-asciinema</a>,安装了下果然可以在博客里面插入asciinema，而且一个超级简单的命令即可完成。像下面就是一个例子(用C++编写一个简单的HelloWorld程序)：<br><script type="text/javascript" src="https://asciinema.org/a/92655.js" id="asciicast-92655" async></script></p>
<p>下面详细介绍每个步骤。<br><a id="more"></a></p>
<h2 id="asciinema安装">asciinema安装</h2><p>参照<a href="https://asciinema.org/docs/installation" target="_blank" rel="external">这里</a>的教程,常见的asciinema的安装方式有下面2种：</p>
<ol>
<li><p>通过系统的包管理软件安装<br>Debian:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install asciinema</span><br></pre></td></tr></table></figure>
<p>Ubuntu:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-add-repository ppa:zanchey/asciinema</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install asciinema</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>2.通过pip3安装，需要先安装python3<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip3 install asciinema</span><br></pre></td></tr></table></figure></p>
<h2 id="asciinema使用">asciinema使用</h2><p>安装好后，打开终端,输入<code>asciinema rec</code> 开始记录，按<code>Ctrl-D</code>结束记录。<br>结束记录后，会让你选择是否需要上传数据，如果选择<code>Y</code>,则会给出一个URL，点击该URL即可访问你刚才录的视频。<br>另外，你也可以在asciinema官网上注册帐号，这样你所有记录的数据都可以保存在上面，你可以通过<code>asciinema auth</code>来验证帐号。</p>
<h2 id="在Hexo里面插入asciinema的视频">在Hexo里面插入asciinema的视频</h2><p>假设你已经在本地安装好了Hexo博客系统而且已经通过asciinema录制好了视频<strong>并上传到asciinema网站上</strong>。<br>首先是通过<code>npm</code>安装<a href="https://github.com/narongdejsrn/hexo-tag-asciinema" target="_blank" rel="external">hexo-tag-asciinema</a>:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --save hexo-tag-asciinema</span><br></pre></td></tr></table></figure></p>
<p>然后在Hexo博客的<code>markdown</code>文件里面，使用下面的命令来插入视频:<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% asciinema video_id %&#125;</span><br></pre></td></tr></table></figure></p>
<p>其中<code>video_id</code>是你上传的视频的编号，比如你视频所在的页面是<code>https://asciinema.org/a/41100</code>, 那在<code>video_id</code>那里填<code>41100</code>。<br>然后保存markdown文件，执行<code>npm install</code>安装必要的包，再<code>hexo deploy</code>部署你的博客，就可以看到效果了。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="概述">概述</h2><p>前几天发现了一个很有意思的记录终端操作的工具<a href="https://asciinema.org/">asciinema</a>,使用起来异常简单功能却很强大，很佩服开发者的想象力和创造力。<br>今天我在想，能否在Hexo博客里面插入asciinema录的视频呢？Google了一下，发现真的已经有人做出了该功能的插件<a href="https://github.com/narongdejsrn/hexo-tag-asciinema">hexo-tag-asciinema</a>,安装了下果然可以在博客里面插入asciinema，而且一个超级简单的命令即可完成。像下面就是一个例子(用C++编写一个简单的HelloWorld程序)：<br><script type="text/javascript" src="https://asciinema.org/a/92655.js" id="asciicast-92655" async></script></p>
<p>下面详细介绍每个步骤。<br>]]>
    
    </summary>
    
      <category term="Linux" scheme="http://vra.github.io/tags/Linux/"/>
    
      <category term="asciinema" scheme="http://vra.github.io/tags/asciinema/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[在Apache上部署Django项目]]></title>
    <link href="http://vra.github.io/2016/07/19/django-apache-deploy/"/>
    <id>http://vra.github.io/2016/07/19/django-apache-deploy/</id>
    <published>2016-07-19T08:44:59.000Z</published>
    <updated>2017-01-08T09:23:44.594Z</updated>
    <content type="html"><![CDATA[<h3 id="0-概述">0.概述</h3><p>Django是一个基于Python的web开发框架，在实际生产环境中部署的时候，还需要用Apache容器来部署。这里记录下如何在Debian系统中用Aapche和<a href="https://pypi.python.org/pypi/mod_wsgi" target="_blank" rel="external">mod_wsgi模块</a>来部署Django项目。<br><a id="more"></a></p>
<h3 id="1-系统信息">1.系统信息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ uname <span class="operator">-a</span>  </span><br><span class="line">Linux iZ284ov0vfwZ <span class="number">3.2</span>.<span class="number">0</span>-<span class="number">4</span>-amd64 <span class="comment">#1 SMP Debian 3.2.81-1 x86_64 GNU/Linux  </span></span><br><span class="line">$ lsb_release <span class="operator">-a</span>  </span><br><span class="line">No LSB modules are available.  </span><br><span class="line">Distributor ID: Debian  </span><br><span class="line">Description:    Debian GNU/Linux <span class="number">7.11</span> (wheezy) </span><br><span class="line">Release:        <span class="number">7.11</span>  </span><br><span class="line">Codename:       wheezy  </span><br><span class="line">$ sudo apachectl -v  </span><br><span class="line">Server version: Apache/<span class="number">2.2</span>.<span class="number">22</span> (Debian)  </span><br><span class="line">Server built:   Aug <span class="number">18</span> <span class="number">2015</span> <span class="number">09</span>:<span class="number">49</span>:<span class="number">50</span></span><br></pre></td></tr></table></figure>
<p><strong>我用的是Debian发行版，Apache的配置与别的发行版有较大不同，这里以Debian为例进行说明，别的发行版需要进行一定的修改。</strong></p>
<h3 id="2-_安装Django和Apache">2. 安装Django和Apache</h3><p>Django可以通过如下命令安装:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install Django==<span class="number">1.9</span>.<span class="number">0</span> <span class="comment">#设置版本号为1.9.0</span></span><br></pre></td></tr></table></figure></p>
<p> Apache通过不同发行版的包管理命令安装。在debian下，是:<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install apache2</span><br></pre></td></tr></table></figure></p>
<h3 id="3-_安装mod_wsgi模块">3. 安装mod_wsgi模块</h3><p>mod_wsgi可以通过pip安装，但是需要提前在系统安装<code>apache-dev</code>包，但是在Debian发行版上，这个包名叫<code>apache2-prefork-dev</code>，详情参考<a href="http://stackoverflow.com/a/16869017/2932001" target="_blank" rel="external">这里</a>。通过如下命令安装<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install apache2-prefork-dev</span><br></pre></td></tr></table></figure></p>
<p>然后pip 安装mod_wsgi:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install mod_wsgi</span><br></pre></td></tr></table></figure></p>
<p>此外也可以自己编译mod_wsgi。<br>首先从<a href="https://github.com/GrahamDumpleton/mod_wsgi/releases" target="_blank" rel="external">这里</a>下载文件包，然后解压，编译。假设版本是4.5.3，全部命令如下:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/GrahamDumpleton/mod_wsgi/archive/<span class="number">4.5</span>.<span class="number">3</span>.tar.gz  </span><br><span class="line">tar -xvf <span class="number">4.5</span>.<span class="number">3</span>.tar.gz  </span><br><span class="line"><span class="built_in">cd</span> mod_wsgi-<span class="number">4.5</span>.<span class="number">3</span>  </span><br><span class="line">./configure  </span><br><span class="line">make  </span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure></p>
<p>如果没有报错，那么mod_wsgi就编译好了!<br><strong>编译好后，会在apache的模块目录<code>/usr/lib/apache2/modules/</code>生成mod_wsgi.so文件。</strong></p>
<h3 id="4-_写配置文件">4. 写配置文件</h3><p>Apache的配置文件目录是<code>/etc/apache2</code>，下面有好几个文件夹，所有的配置文件都会包含在最终的<code>apache2.conf</code>中，所以我们写在.conf的文件默认对全局都起作用，所以这样配置并不规范，但作为一个尝试性的配置，这里姑妄错之。默认使用80端口作为我们网站的监听端口。我们需要在<code>mods-available</code>目录下新建<code>mod_wsgi</code>的load文件和conf文件，具体操作如下:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/apache2/mod-available  </span><br><span class="line">sudo <span class="built_in">echo</span> <span class="string">" LoadModule wsgi_module /usr/lib/apache2/modules/mod_wsgi.so"</span> &gt;&gt; wsgi.load  </span><br><span class="line">sudo vi wsgi.conf</span><br></pre></td></tr></table></figure></p>
<p>然后在<code>wsgi.conf</code>中写入如下内容:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">WSGIScriptAlias / /path/to/mysit.com/mysite/wsgi.py  </span><br><span class="line">WSGIPythonPath /path/to/mysite.com  </span><br><span class="line">&lt;Directory /path/to/mysite.com/mysite&gt;  </span><br><span class="line">&lt;Files wsgi.py&gt;  </span><br><span class="line"> 	Order deny,allow  </span><br><span class="line">    Allow from all  </span><br><span class="line">&lt;/Files&gt;  </span><br><span class="line">&lt;/Directory&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>注意对于版本大于2.4的Apache，需要将<code>&lt;Files&gt;</code>标签中的两句话改为<code>Require all granted</code>。</strong><br>此外，静态文件和媒体文件也都由Apache来托管，故还需要将<code>media</code>目录和<code>static</code>目录的配置路径也加入到wsgi.conf配置文件中，命令如下:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Alias /media/ /path/to/media/  </span><br><span class="line">Alias /static/ /path/to/static/  </span><br><span class="line">&lt;Directory /path/to/static&gt;  </span><br><span class="line">    Order deny,allow  </span><br><span class="line">    Allow from all  </span><br><span class="line">&lt;/Directory&gt;  </span><br><span class="line">&lt;Directory /path/to/media&gt;  </span><br><span class="line">    Order deny,allow  </span><br><span class="line">    Allow from all  </span><br><span class="line">&lt;/Directory&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>同样地，对于2.4以上的Apache版本，需要将<code>Order deny,allow</code> 和<code>Allow from all</code>改为<code>Require all granted</code>。</strong><br>最后wsgi.conf的内容如下:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">WSGIScriptAlias / /path/to/mysite.com/mysite/wsgi.py</span><br><span class="line">WSGIPythonPath /path/to/mysite.com</span><br><span class="line">&lt;Directory /path/to/mysite.com/mysite&gt;</span><br><span class="line">	&lt;Files wsgi.py&gt;</span><br><span class="line"> 		Order deny,allow</span><br><span class="line">    	Allow from all</span><br><span class="line">	&lt;/Files&gt;</span><br><span class="line">&lt;/Directory&gt;</span><br><span class="line">Alias /media/ /path/to/media/</span><br><span class="line">Alias /static/ /path/to/static/</span><br><span class="line">&lt;Directory /path/to/static&gt;</span><br><span class="line">    Order deny,allow</span><br><span class="line">    Allow from all</span><br><span class="line">&lt;/Directory&gt;</span><br><span class="line">&lt;Directory /path/to/media&gt;</span><br><span class="line">    Order deny,allow</span><br><span class="line">    Allow from all</span><br><span class="line">&lt;/Directory&gt;</span><br></pre></td></tr></table></figure></p>
<p>Django项目的配置文件<code>settings.py</code>也需要修改下面这几个地方:</p>
<ol>
<li><code>DEBUG=False</code></li>
<li><code>ALLOWED_HOSTS</code> 需要设置，不可以为空。如果是本地，可以写成<code>127.0.0.0</code>，有IP地址的，可以直接写IP地址</li>
<li><code>TEMPLATE中</code>的<code>DIRS</code>变量需要设置一个绝对路径，而不能继续用相对路径<h3 id="5-_启用wsgi模块">5. 启用wsgi模块</h3>配置完后，启用wsgi模块，重启apache服务器<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo a2enmod wsgi</span><br><span class="line">sudo service apache2 restart</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>打开浏览器，输入<code>localhost</code>或者IP地址，应该就可以看到你的网站内容了。<br>如果要想监听别的端口，可以在<code>ports.conf</code>里面输入如下几行:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NameVirtualHost *:<span class="number">8020</span></span><br><span class="line">Listen <span class="number">8020</span></span><br></pre></td></tr></table></figure></p>
<p>这里举例来监听8020端口。之后应该就能在8020端口访问你的网站了。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="0-概述">0.概述</h3><p>Django是一个基于Python的web开发框架，在实际生产环境中部署的时候，还需要用Apache容器来部署。这里记录下如何在Debian系统中用Aapche和<a href="https://pypi.python.org/pypi/mod_wsgi">mod_wsgi模块</a>来部署Django项目。<br>]]>
    
    </summary>
    
      <category term="Apache" scheme="http://vra.github.io/tags/Apache/"/>
    
      <category term="Django" scheme="http://vra.github.io/tags/Django/"/>
    
      <category term="Python" scheme="http://vra.github.io/tags/Python/"/>
    
      <category term="Web编程" scheme="http://vra.github.io/tags/Web%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[OpenMP并行编程简介]]></title>
    <link href="http://vra.github.io/2016/06/17/openmp-begin/"/>
    <id>http://vra.github.io/2016/06/17/openmp-begin/</id>
    <published>2016-06-17T13:49:56.000Z</published>
    <updated>2017-01-08T09:23:44.566Z</updated>
    <content type="html"><![CDATA[<p>在这学期的并行计算课程中，老师讲了OpenMP,MPI，CUDA这3种并行计算编程模型，我打算把相关的知识点记录下来，便于以后用到的时候查阅。  </p>
<p><img src="http://www.openmp.org/wp-content/uploads/openmp-menu-logo.jpg" alt="openmp log"></p>
<a id="more"></a>
<h2 id="概述">概述</h2><p>OpenMP是基于共享存储体系的基于线程的并行编程模型。一个共享存储的进程由多个线程组成，而OpenMP就是基于已有线程的共享编程范例。<br>在OpenMP中，线程的并行化是由编程人员控制的，不是自动编程模型，而是外部变成模型。<br>OpenMP采用<strong>Fork-Join</strong>并行执行模型。即程序开始于一个单独的主线程，主线程会一直串行地执行，遇到第一个并行域，通过如下过程完成并行操作：  </p>
<ol>
<li>Fork: 主线程创建一系列并行的线程，由这些线程来完成并行域的代码。  </li>
<li>当所有并行线程完成代码的执行后，它们或被同步或被中断，最后只剩下主线程在执行。</li>
</ol>
<p>那么并行代码块是如何创建的呢？在OpenMP中，通过编译制导语句（即像<code>#pragma</code>开头的语句）来构造并行域，在原本的串行代码中，在可并行代码块周围添加编译制导语句并修改相应的代码，就可以完成并行的功能。<br>运行OpenMP代码不需要安装任何额外的库或工具，标准的C/C++代码编译器执行环境就可以执行。<br>下面是一个简单的OpenMP的例子：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file name: test_openmp.c</span></span><br><span class="line"><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;omp.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> num_thread = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">	omp_set_num_threads(num_thread);</span><br><span class="line">	<span class="preprocessor">#<span class="keyword">pragma</span> omp parallel</span></span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">int</span> id = omp_get_thread_num();</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"hello from thread%d\n"</span>,id);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>通过<code>gcc --openmp test_openmp.c</code>来编译，运行生成的可执行文件，得到结果如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hello from thread0&#10;hello from thread3&#10;hello from thread1&#10;hello from thread2</span><br></pre></td></tr></table></figure></p>
<p>可以看到，各个线程执行的顺序是无序的。  </p>
<h2 id="核心知识">核心知识</h2><p>下面记录使用OpenMP的一些核心点。  </p>
<ol>
<li>包含头文件<code>omp.h</code></li>
<li>所有并行块由<code>#pragma omp</code>开头的编译制导语句来开始，在代码块周围要有大括号</li>
<li>常见的编译制导语句有<code>#pragma omp prallel</code>, 表示最基本的循环</li>
<li><code>#pragma omp parallel for</code>:并行部分包含一个for循环;</li>
<li><code>#pragma omp critical</code>:并行部分的代码一次只能由一个线程执行，相当于取消了并行化</li>
<li><code>#pragma omp barrier</code>: 同步并行线程，让线程等待，直到所有的线程都执行到该行</li>
<li><code>#pragma omp section</code>: 将并行块内部的代码划分给线程组中的各个线程，一般会在内部嵌套几个独立的<code>section</code>语句，可以使用<code>nowait</code>来停止等待 </li>
<li>通过<code>omp_set_num_threads</code>函数来手动设置线程数。可以看到线程数是在程序编写过程中指定的</li>
<li>通过<code>omp_get_thread_num</code>来获取当前线程的编号</li>
<li>通过<code>omp_get_num_threads</code>来获取线程总数</li>
</ol>
<h2 id="一个例子">一个例子</h2><p>这里举一个更完善的例子来说明。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;time.h&gt;</span></span></span><br><span class="line"><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;omp.h&gt;</span></span></span><br><span class="line"><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;sys/time.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">	<span class="keyword">struct</span> timeval start, end;</span><br><span class="line">	gettimeofday(&amp;start, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (argc != <span class="number">3</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"USAGE: num_primer &lt;num_of_thread&gt; &lt;integer&gt;"</span> &lt;&lt; <span class="built_in">std</span>::endl;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> num_thread = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">    <span class="keyword">int</span> n = atoi(argv[<span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"num of thread: "</span> &lt;&lt; num_thread &lt;&lt; <span class="built_in">std</span>::endl;</span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">" n: "</span> &lt;&lt; n &lt;&lt; <span class="built_in">std</span>::endl;</span><br><span class="line">    <span class="keyword">int</span>* num_primer = <span class="keyword">new</span> <span class="keyword">int</span>[num_thread];</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_thread; ++i)</span><br><span class="line">	&#123;</span><br><span class="line">		num_primer[i] = <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	omp_set_num_threads(num_thread);</span><br><span class="line">	<span class="preprocessor">#<span class="keyword">pragma</span> omp parallel shared(n, num_primer)</span></span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">int</span> id = omp_get_thread_num();</span><br><span class="line">		</span><br><span class="line">    	<span class="keyword">for</span> (<span class="keyword">int</span> i = id + <span class="number">2</span>; i &lt; n + <span class="number">1</span>; i = i + num_thread)</span><br><span class="line">    	&#123;</span><br><span class="line">			<span class="keyword">bool</span> has_factor = <span class="literal">false</span>;</span><br><span class="line">			<span class="preprocessor">#<span class="keyword">pragma</span> omp parallel shared(n, i, num_primer, has_factor)</span></span><br><span class="line">			&#123;</span><br><span class="line">				<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">2</span>; j &lt; <span class="keyword">int</span>(<span class="built_in">sqrt</span>(i)) + <span class="number">1</span>; ++j)</span><br><span class="line">				&#123;</span><br><span class="line">					<span class="keyword">if</span> (i % j == <span class="number">0</span>)</span><br><span class="line">					&#123;</span><br><span class="line">						has_factor = <span class="literal">true</span>;</span><br><span class="line">						<span class="keyword">break</span>;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">if</span> (!has_factor)</span><br><span class="line">				&#123;</span><br><span class="line">					++num_primer[id];</span><br><span class="line">					<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"id: "</span>&lt;&lt; id &lt;&lt; <span class="string">", primer:"</span> &lt;&lt; i &lt;&lt; <span class="built_in">std</span>::endl;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;<span class="comment">//pragma</span></span><br><span class="line">    	&#125;</span><br><span class="line">	&#125;<span class="comment">//pragma</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">//add all primers</span></span><br><span class="line">	<span class="keyword">int</span> sum_num_primer = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_thread; ++i)</span><br><span class="line">	&#123;</span><br><span class="line">		sum_num_primer += num_primer[i];	</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"The number of primers between 0 and "</span> &lt;&lt; n &lt;&lt; <span class="string">" is: "</span> &lt;&lt; sum_num_primer &lt;&lt; <span class="built_in">std</span>::endl;</span><br><span class="line"></span><br><span class="line">	gettimeofday(&amp;end, <span class="literal">NULL</span>);</span><br><span class="line">	<span class="keyword">double</span> time_gap = (end.tv_sec - start.tv_sec) * <span class="number">1000000u</span> + end.tv_usec - start.tv_usec;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"Time cost: %.2lf s.\n"</span>, time_gap / <span class="number">100000</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="参考文献">参考文献</h2><p>并行计算——结构，算法，编程（第3版），陈国良</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在这学期的并行计算课程中，老师讲了OpenMP,MPI，CUDA这3种并行计算编程模型，我打算把相关的知识点记录下来，便于以后用到的时候查阅。  </p>
<p><img src="http://www.openmp.org/wp-content/uploads/openmp-menu-logo.jpg" alt="openmp log"></p>]]>
    
    </summary>
    
      <category term="C/C++" scheme="http://vra.github.io/tags/C-C/"/>
    
      <category term="OpenMP" scheme="http://vra.github.io/tags/OpenMP/"/>
    
      <category term="并行计算" scheme="http://vra.github.io/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Spark简介]]></title>
    <link href="http://vra.github.io/2016/06/16/spark/"/>
    <id>http://vra.github.io/2016/06/16/spark/</id>
    <published>2016-06-16T13:24:30.000Z</published>
    <updated>2017-01-08T09:23:44.674Z</updated>
    <content type="html"><![CDATA[<h2 id="概述">概述</h2><p>这篇文章是我通过学习了Spark官网上的一些内容，参考了许多博客和文章，也尝试进行了一些初级的Spark编程后写的关于Spark的简要的说明，希望能讲明白Spark这个框架的一些原理，提供一个基础的入门教程。  </p>
<p><img src="http://spark.apache.org/images/spark-logo-trademark.png" alt="Spark logo">    </p>
<a id="more"></a>
<p>Spark是一个用于分布式数据处理和并行计算的开源项目，最早由UC Berkeley 的AMP 实验室开发，现在已经交由Apache开源项目组管理。Spark目前变得非常流行，跟其高效性，通用性和易于编程性都有很大关系。Spark在机器学习，大数据处理和实时数据处理，以及分布式的应用场景中都能充分发挥作用。  </p>
<p><strong>Spark程序计算很快。</strong> 根据<a href="http://spark.apache.org/" target="_blank" rel="external">Spark主页</a>上的描述，Spark程序比基于Memory的<a href="http://hadoop.apache.org/" target="_blank" rel="external">Hadoop</a>(一个分布式系统基础架构)的MapReduce要快100倍，比基于硬盘的Hadoop MapReduce 快10倍。Spark之所以有如此快的速度，是因为采用了很多高效的方案，如采用懒惰模式，基于内存进行操作，对数据进行多种方式的缓存等等。  </p>
<p><strong>Spark程序易于编写。</strong> Spark 原生是由Scala编写，现在支持Java，Scala，Python和R四种语言。这四种语言可以覆盖较大的开发者范围，像R是数据处理专家的拿手语言，而Java是Hadoop的开发语言，而且由于Spark对Hadoop的一定程度的兼容性，使得Hadoop开发者可以快速地转到Spark平台上来。而Python和Scala是现代化的编程语言，编程风格优雅，入门简单，所以开发者可以快速地开发出可以实际应用的程序。  </p>
<p><strong>Spark统一了本地和分布式情形下的数据访问模式</strong>。在本地电脑上，Spark会开多个进程来模拟分布式环境下的任务计算，所以即使在单机环境下，开发者也可以编写适用于分布式环境的程序，这大大地简化了程序的调试难度，也进一步加快了项目的开发进程。另外，Spark提出了弹性分布式数据集（RDD， Resilient Distributed Dataset）的数据格式,这种格式的数据默认就是分布式分布地，但是操作方式却和本地操作方式一样，即替开发者完成了运算节点之间拷贝数据的操作，使得开发人员像编写本地程序一样来编写分布式程序，毫无疑问这是一个很大的优势。    </p>
<p>上面是一些比较大范围的说明，而我个人对Spark比较向往的地方则是相比Hadoop，Spark上手很容易，官网上提供的教程和说明非常详尽，自己写一个计算$\pi$的程序只需要以下几行Python代码即可完成（代码来自Spark官方给出的例子）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> add</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="string">"""</span><br><span class="line">        Usage: pi [partitions]</span><br><span class="line">    """</span></span><br><span class="line">    sc = SparkContext(appName=<span class="string">"PythonPi"</span>)</span><br><span class="line">    partitions = int(sys.argv[<span class="number">1</span>]) <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">    n = <span class="number">100000</span> * partitions</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(_)</span>:</span></span><br><span class="line">        x = random() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">        y = random() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> x ** <span class="number">2</span> + y ** <span class="number">2</span> &lt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    count = sc.parallelize(range(<span class="number">1</span>, n + <span class="number">1</span>), partitions).map(f).reduce(add)</span><br><span class="line">    print(<span class="string">"Pi is roughly %f"</span> % (<span class="number">4.0</span> * count / n))</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br></pre></td></tr></table></figure></p>
<p>可以看到，核心代码不超过10行。    </p>
<p>而为了配置Hadoop，我花了2天的时间，也还没有搞好，实在是对入门者不够友好。此外Java编写的程序和XML编写的配置文件一开始就有一种很“重”的感觉，使人望而却步。   </p>
<p>上面这部分内容是关于Spark的一个大概的介绍，<strong>下面，我将从核心概念，集群模型和编程体验这三个大的方向进行详细的说明和我的理解。注意：下面的示例都以Spark的Python API为例。</strong></p>
<h2 id="核心概念">核心概念</h2><h2 id="1-_SparkContext">1. SparkContext</h2><p>Spark是管理集群和协调集群进程的对象。SparkContext就像任务的分配和总调度师一样，处理数据分配，任务切分这些任务。下图是Spark官网给出的集群之间的逻辑框架图，可以看到SparkContext在Driver程序中运行，这里的Driver就是主进程的意思。Worker Node就是集群的计算节点，计算任务在它们上完成。<br><img src="http://spark.apache.org/docs/latest/img/cluster-overview.png" alt="Spark集群逻辑框架"></p>
<p>Spark提供了Scala和Python的交互式命令环境，里面默认会创建一个<code>SparkContext</code>变量，并将其重命名为<code>sc</code>，所以在交互式环境下，可以用<code>sc</code>来方便地调用<code>SparkContext</code>的函数集合。下面示例中采用<code>sc</code>来代表<code>SparkContext</code>。  </p>
<h3 id="2-_RDD">2. RDD</h3><p>RDD是Resilient Distributed Datasets的缩写，中文翻译为弹性分布式数据集，它是Spark的数据操作元素，是具有容错性的并行的基本单元。<strong>RDD之于Spark，就相当于array之于Numpy，Matrix之于MatLab，DataFrames之于Pandas。</strong> 很重要的一个点是：RDD天然就是在分布式机器上存储的，比如对于下面这个RDD数据,可能Data1-3是存储在节点1的，Data4-6是存储节点2的，后面的数据也是这样，存储在集群中不同的机器上的。这种碎片化的存储使得任务的并行变得容易。    </p>
<p><img src="http://img.ptcms.csdn.net/article/201511/25/5655b0ea512a8.jpg" alt="RDD data"></p>
<p>RDD生成也很容易，可以由串行的List， Tuple等等来生成，如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>]</span><br><span class="line">dist_data = sc.parallelize(data)</span><br></pre></td></tr></table></figure></p>
<p>这两行代码就可以将串行的数据转换为并行的RDD。  </p>
<p>另一种生成RDD的方法是从外部的存储系统进行引用，如可以从硬盘上的文件（像‘data.txt’）,HDFS文件系统，HBase数据库，或者任何的提供Hadoop的InputFormat格式的数据来源都可以。对于各种格式的数据，Spark都有专门的处理函数，像<code>textFile</code>用来读取硬盘上的文本文件，按行返回文本中的内容；而<code>newAPIHadoopRDD</code>函数则可以保存/读取符合Haddoop输出/输入格式的文件。具体使用规则请参考<a href="http://spark.apache.org/docs/latest/programming-guide.html" target="_blank" rel="external">Spark编程指南</a>。  </p>
<h3 id="3-_Action_v-s-_Transformation">3. Action v.s. Transformation</h3><p>RDD支持2种操作，一种是<code>Transformation</code>，这种操作的结果是生成一个新的RDD对象，即由RDD生成RDD，如Transformation操作<code>map</code>，就是对RDD中的每个数据，对应生成map函数中定义的数据，最后得到的还是一个RDD。举个具体的例子，假设map函数是：对RDD中的每个数据加1，假设原先的数据是[1,3,5,7,9],则这个map函数作用的结果是[2,4,6,8,10],仍然是个RDD（注意：这里为了方便解释，将RDD写出Python中的List形式，实际上要记得这里的RDD数据是保存在不同机器上的）。另一种操作叫做<code>Action</code>，这种操作的结果是得到一个值(Value)。即由RDD得到Value。如Action操作<code>reduce</code>，假设reduce函数设定为：求RDD中所有元素的和，则对该RDD作用reduce的结果是30,为一个值。  </p>
<p>常见的<code>Tranformation</code>操作包括<code>map，filter，flatMap,mapPartions, mapPartitionsWithIndex, sample, union, intersection, distinct, groupByKey, reduceByKey, aggregateByKey, sortByKey, join, pipe</code>等。<br>常见的<code>Action</code>操作包括<code>reduce，collect，count，first，take，takeSampke， takeOrdered， countByKey, foreach</code>等等。  </p>
<h3 id="4-_Lazy_Evalution">4. Lazy Evalution</h3><p>Spark采用了惰性计算。所谓惰性计算，即对所有<code>transformation</code>，不会立即执行，而是等到某个<code>action</code>作用的时候，需要向Driver发送结果的时候再执行之前的所有<code>transformation</code>。简单来说，就是所有任务都拖到不能再拖的时候再执行。  </p>
<p>惰性计算能提高Spark运行的性能。试想，如果对所有的<code>transformation</code>操作，立即计算，然后向Dirver返回结果，则需要发送数目巨大的数据集；而如果采用惰性计算，则只需发送最后的一个值给Driver，传输开销会大大地减小。  </p>
<p><strong>需要指出的是：在Spark中，所有<code>transformation</code>操作都采用惰性模式，而所有<code>action</code>都是非惰性模式。</strong></p>
<h3 id="5-_Closure">5. Closure</h3><p>在Spark中执行某一项任务的时候，Spark driver程序会将RDD的的操作分配到各个计算节点上，Spark称这些计算节点为<code>executor</code>。而每个executor执行计算的变量和操作就称为这个executor的<code>Closure</code>。  </p>
<p>需要注意的是，各个executor的closure是不同的，刚开始的时候数据都从driver程序中克隆过来，之后这些数据就和driver程序中的数据没有任何关系了。这里可以类比<code>fork</code>操作，子进程和父进程之间的数据是隔离的，互不影响的。  </p>
<p><strong>由于各个executor和driver的数据是不同的，所以涉及到不同节点上同名变量的运算，结果结果是不确定的，也不要依赖于该运算结果。</strong></p>
<h3 id="6-_Shuffle">6. Shuffle</h3><p>在Spark中，有的时候为了执行某一个操作，需要从多个节点获取数据到一个节点，然后进行计算。计算后将计算结果再传给相应的计算节点。这个过程中，计算前后对应节点的数据是对应的，即节点1的计算结果还是返回到节点1,但是返回的顺序可能发生了改变，如节点1原先顺序是[2,3,4],可能结果是按[3,2,4]的计算结果返回的，这样就间接地完成了一个打乱顺序的操作，在Spark中称以上这个过程为<code>shuffle</code>。</p>
<p>由上述描述可以看出来，Shuffle操作是一个开销比较大的操作，需要较大量的硬盘IO，数据串行化操作，和网络IO。此外，为了在单个节点保存多个节点上传过来的数据，还需要消耗较大的内存空间。  </p>
<p>此外，Spark内部会隐式地<strong>在硬盘上</strong>保存该过程中产生的中间文件，以便于以后再次使用。过一定时间后，或者数据不再使用时，垃圾回收机器（GC，Garbage Collection）就会删除这些文件。由于GC回收的时间间隔会比较长，所以在运行Spark的过程中会产生很多的中间数据，占据很多的硬盘空间，所以Spark快，是以占据大量内存空间和磁盘空间作为代价的。  </p>
<h3 id="7-_Persistance">7. Persistance</h3><p>为了加快运行的速度，Spark提供了<code>persist</code>和<code>cache</code>函数由开发者来显式地缓存RDD数据。在初次执行某个<code>action</code>的时候，对RDD数据进行缓存，在以后的<code>action</code>操作中，直接读取缓存的RDD数据。这样下来，<code>action</code>的执行速度可以提升10倍。<br>Spark的缓存具有容错性，如果一个节点的RDD数据部分丢失了，则Spark会根据生成该部分RDD数据的<code>transformation</code>重新生成完全一样的数据。  </p>
<p>此外，Spark还允许设置不同的缓存存储级别（<code>StorageLevel</code>），如只缓存在内存中（<code>MEMORY_ONLY</code>），缓存在内存和硬盘中（<code>MEMORY_AND_DISK</code>），等等。这些参数可以通过<code>persist</code>函数进行设置。而<code>cache</code>函数则是<code>persist</code>函数指定<code>StorageLevel</code>为<code>MEMORY_ONLY</code>时的简写。    </p>
<p>本质上StorageLevel的选取，是在内存占用量和CPU高效性之间的平衡。Spark官方文档中推荐使用<code>MEMORY_ONLY</code>，如果不行，可以选用<code>MEMROY_ONLY_SER</code>，这中方式类似于前者，只不过是串行存储以节省开销。一般不建议用<code>DISK</code>相关的存储。  </p>
<p>Spark会自动监控缓存数据的使用情况，如果空间不够的话，就会使用最近使用次数最少算法（LRU，Least-Recently -Used）将部分缓存数据给删除掉。如果你想手动删除缓存，可以调用<code>RDD.unpersist()</code>函数。  </p>
<h3 id="8-_Shared_Variables">8. Shared Variables</h3><p>通常情况下，当Driver程序给各个cluster节点分配后任务，复制完初始数据后，各个节点就在自己的本地空间上单独进行计算，再也不会和Driver程序之间发送数据了。但是为了几个非常常用的操作，Spark提供了2类共享变量：<code>broadcast variable</code>和<code>accumulator</code>。  </p>
<p>broadcast变量是一种只读的变量，在driver进程需要向多个机器发送相同数据的时候会用到。并且规定boroadcast变量在广播后不可以被改变。我们可以对变量<code>v</code>进行broadcast操作，对其进行广播，然后在各个机器上使用的时候，使用<code>.value</code>来读取，而不是直接读取<code>v</code>的值。如下例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">broadcastVar = sc.broadcast([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">broadcastVar.value </span><br><span class="line"><span class="comment">#结果：[1, 2, 3]</span></span><br></pre></td></tr></table></figure></p>
<p>可以看到原理跟MPI里面的<code>MPI_Broadcast</code>函数的原理是比较类似的。  </p>
<p>另一种共享变量是Accumulator，通过<code>SparkContext.accumulator(v)</code>函数初始化为<code>v</code>，然后可以通过将各个进程中的值增加到这个变量上面，然后计算得到相应的值。Spark内置了数值类型的Accumulator变量，开发者可以自己实现别的类型的Accumulator变量。其值也通过<code>value</code>属性来获得。下面是一个计算各个节点上数据之和的例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">accum = sc.accumulator(<span class="number">0</span>)</span><br><span class="line">sc.parallelize([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]).foreach(<span class="keyword">lambda</span> x: accum.add(x))</span><br><span class="line">accum.value </span><br><span class="line"><span class="comment">#结果：10</span></span><br></pre></td></tr></table></figure></p>
<h2 id="集群模型">集群模型</h2><p>结束了冗长而且枯燥的概念部分后，下面我来阐述一下关于Spark集群模型的一些理解。  </p>
<h3 id="1-_Cluster模型">1. Cluster模型</h3><p><img src="http://spark.apache.org/docs/latest/img/cluster-overview.png" alt="Spark Cluster Model"><br>上图是官网给出的Spark集群模型，Driver Program 是主进程，SparkContext运行在它上面，它跟Cluster Manager相连。Driver对Cluster Manager下达任务人，然后由Cluster Manager将任资源分配给各个计算节点(Worker Node)上的<code>executor</code>，然后Driver再将应用的代码发送给各个Worker Node。最后，Driver向各个节点发送<code>Task</code>来运行。  </p>
<p>这里有几个需要注意的点：</p>
<blockquote>
<ul>
<li>在Spark中，各个应用之间数据是隔离的，即不同的SparkContext之间互不可见。这样能有效地保护数据的局部性。  </li>
<li>Cluster Manager对Driver来说是不知的，透明的，只要能满足要求就可以。所以Spark可以在Mesos和YARN这些Cluster Manager上运行。  </li>
<li>在运行过程中，Driver需要随时准备好接收来自各个计算节点的数据，所以对各个executor来说，Driver必须是可寻址的，比如有公网IP，或者如果在同一个局域网的话，有固定的局域网IP。  </li>
<li>由于Driver需要随时接收消息和数据，所以最好Driver和各个节点比较邻近，这样数据传输会比较快。  </li>
</ul>
</blockquote>
<h3 id="2-_Cluster_Manager_类型">2. Cluster Manager 类型</h3><p>当前Spark支持3种类型的Cluster Manager,分别是：</p>
<blockquote>
<ul>
<li><code>Apache Mesos</code>： <a href="http://spark.apache.org/docs/latest/running-on-mesos.html" target="_blank" rel="external">Mesos</a>是一种通用的的集群管理系统，可以运行Hadoop和别的分布式计算。</li>
<li><code>Hadoop YARN</code>: 这是Hadoop 2 默认的资源管理系统。</li>
<li><code>Standalone</code>-这种类型是Spark单独设计的管理系统，比较简单，也没有太多的需要预先学习的东西。</li>
</ul>
</blockquote>
<h3 id="3-_概念辨析">3. 概念辨析</h3><p>Spark集群模型有许多概念，之间的区别还是需要仔细辨析才能搞清楚。下面是从官方网站上抄录下来的一个定义，因为怕翻译后改变原意所以这里没有翻译，仅给出原文供参考：  </p>
<blockquote>
<ul>
<li><code>Application</code> : User program built on Spark. Consists of a driver program and executors on the cluster.  </li>
<li><code>Application jar</code> : A jar containing the user’s Spark application. In some cases users will want to create an “uber jar” containing their application along with its dependencies. The user’s jar should never include Hadoop or Spark libraries, however, these will be added at runtime.  </li>
<li><code>Driver program</code> : The process running the main() function of the application and creating the SparkContext  </li>
<li><code>Cluster manager</code> : An external service for acquiring resources on the cluster (e.g. standalone manager, Mesos, YARN)  </li>
<li><code>Deploy mode</code> : Distinguishes where the driver process runs. In “cluster” mode, the framework launches the driver inside of the cluster. In “client” mode, the submitter launches the driver outside of the cluster.</li>
<li><code>Worker node</code> : Any node that can run application code in the cluster</li>
<li><code>Executor</code> : A process launched for an application on a worker node, that runs tasks and keeps data in memory or disk storage across them. Each application has its own executors.</li>
<li><code>Task</code>: A unit of work that will be sent to one executor</li>
<li><code>Job</code> : A parallel computation consisting of multiple tasks that gets spawned in response to a Spark action (e.g. save, collect); you’ll see this term used in the driver’s logs.</li>
<li><code>Stage</code> : Each job gets divided into smaller sets of tasks called stages that depend on each other (similar to the map and reduce stages in MapReduce); you’ll see this term used in the driver’s logs.</li>
</ul>
</blockquote>
<h3 id="4-_资源监控">4. 资源监控</h3><p>Spark在运行过程中，会在Driver程序所在机器的4040端口显示关于运行任务，存储情况和工作节点等等的Web UI。对于Standalone模式，在7070端口有类似的信息展示。开发者可以通过访问这个Web UI来了解更多信息。  </p>
<p>集群模型就这些内容，下面以Python编程为例，展示Spark编程的风格和思路。  </p>
<h2 id="编程体验">编程体验</h2><p>在这部分，我以WordCount 和计算PI这2个程序作为例子，描述如何用Python进行Spark编程。</p>
<h3 id="1-_下载Spark程序">1. 下载Spark程序</h3><p>从<a href="http://spark.apache.org/downloads.html" target="_blank" rel="external">Spark官方下载页面</a>选择一个合适版本的Spark。建议在<code>package type</code>这一栏选择<code>Pre-built for Hadoop 2.x and later</code>，这样下载下来的版本会自带Hadoop相关的东西，不用自己单独再配Hadoop。<br>下载下来后，解压即可：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xvf spark-*.tgz</span><br></pre></td></tr></table></figure></p>
<h3 id="2-_打开Python命令行">2. 打开Python命令行</h3><p>进入解压后的目录，输入<code>./bin/pyspark</code>即可打开Python交互式窗口。这里会采用系统默认的Python交互式界面，如果想用体验更好的IPython交互式界面，则可以在输入命令之前设置如下环境变量：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PYSPARK_DRIVER_PYTHON=ipython ./bin/pyspark</span><br></pre></td></tr></table></figure></p>
<p>然后输入<code>./bin/pyspark</code>即可进入IPython。<br>前面也提到过，在命令行下，SparkContext会自动创建好，并重命名为sc，所以下面可以直接使用sc来进行操作。  </p>
<h3 id="3-_读取Spark根目录下REAMDE-md中出现Spark这个单词的行数">3. 读取Spark根目录下<code>REAMDE.md</code>中出现<code>Spark</code>这个单词的行数</h3><p>为了完成这个任务，我们首先读取<code>README.md</code>作为RDD数据。还记得RDD吗？这是Spark默认的处理类型，默认就是分布式存储的。读取本地文本文件使用<code>textFile</code>函数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">readMeFile = sc.textFile(<span class="string">'README.md'</span>)</span><br></pre></td></tr></table></figure></p>
<p>读进来的文件存在readMeFile这个RDD类型数据中，按行存储，其中每行就是<code>README.md</code>文件中的一行。<br>然后可以使用<code>filter</code>操作来获取满足条件的数据：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">linesWithSpark = readMeFile.filter(<span class="keyword">lambda</span> line : <span class="string">"Spark"</span> <span class="keyword">in</span> line)</span><br></pre></td></tr></table></figure></p>
<p>这里<code>filter</code>函数返回满足里面lambda函数的新的RDD数据。lambda函数是Python中一种单行的函数，以一个语句来实现一个函数的功能。lambda后面紧跟的那个引号之前的变量为输入参数，引号后面的内容为输出结果，如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lambda</span> x, y : x + y</span><br></pre></td></tr></table></figure></p>
<p>就是返回x和y之和的一个lambda函数。<br>要注意的是得到的RDD虽然是只包含字符串”Spark”的那些行，但还是分布式存储的。为了得到具体的行数，我们可以采用<code>count</code>函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">linesWithSpark.count()</span><br><span class="line"><span class="comment">#结果：15</span></span><br></pre></td></tr></table></figure></p>
<p>此外，我们还可以把以上所有的<code>transformation</code>操作都以链式方式写在一起，如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">readMeFile.filter(<span class="keyword">lambda</span> line : <span class="string">"Spark"</span> <span class="keyword">in</span> line).count()</span><br></pre></td></tr></table></figure></p>
<p>如果将上述代码写成单独的可执行的Python文件，内容将会是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"></span><br><span class="line">sc = SparkContext(appName=<span class="string">"WordCount"</span>)</span><br><span class="line">readMeFile = sc.textFile(<span class="string">'README.md'</span>)</span><br><span class="line">readMeFile.filter(<span class="keyword">lambda</span> line : <span class="string">'Spark'</span> <span class="keyword">in</span> line).count()</span><br></pre></td></tr></table></figure></p>
<p>可以看到，很简单吧，下面我们继续来看用Spark来计算Pi值的例子。  </p>
<h3 id="4-_用Spark计算Pi（采用随机投点法）">4. 用Spark计算Pi（采用随机投点法）</h3><p>所谓随机投点法，是根据圆和其外接正方形的面积之比为PI/4，因此我们可以统计在这个单位正方形内随机投点时，落入圆的比例为多少，投点数量足够多时，这个比例近似为PI/4,然后这个比例*4即为PI值。实际投点时，采取第一象限的[0,1]x[0,1]区域即可。<br>首先我们定义一个函数<code>f</code>,这个函数进行每次随机投点的统计，是否落在圆内，落在圆内返回1,否则返回0：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> random</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(_)</span>:</span></span><br><span class="line">    x = random() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">    y = random() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> x ** <span class="number">2</span> + y ** <span class="number">2</span> &lt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>之后，我们共进行10^6次试验，每次试验调用f函数，然后把所有结果相加，最后再*4/10^6即为PI的估计。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">10</span>**<span class="number">6</span></span><br><span class="line">count = sc.parallelize(range(<span class="number">1</span>,n+<span class="number">1</span>)).map(f).reduce(<span class="keyword">lambda</span> x, y : x + y)</span><br><span class="line">pi = <span class="number">4.0</span> * count / n</span><br><span class="line">print(<span class="string">'*****result: pi is :%f*****'</span> %(pi))</span><br></pre></td></tr></table></figure></p>
<p>其中第2行为主要的计算任务，搞懂这一行的操作大概就能明白Spark是怎么工作的了。<br>将上述代码完成写出来，如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#file name: calc_pi.py</span></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">sc = SparkContext(appName=<span class="string">'CalcPi'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(_)</span>:</span></span><br><span class="line">    x = random() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">    y = random() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> x ** <span class="number">2</span> + y ** <span class="number">2</span> &lt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">n = <span class="number">10</span> ** <span class="number">6</span></span><br><span class="line">count = sc.parallelize(range(<span class="number">1</span>, n + <span class="number">1</span>)).map(f).reduce(<span class="keyword">lambda</span> x, y : x + y)</span><br><span class="line">pi = <span class="number">4.0</span> * count / n</span><br><span class="line"></span><br><span class="line">print(<span class="string">'*****result: pi is :%f*****'</span> %(pi))</span><br></pre></td></tr></table></figure></p>
<p>可以看到，内容很简洁，比MPI复杂的函数命名简洁多了。<br>之后，在Spark根目录中，使用如下命令开始运行Spark进行计算：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit calc_pi.py</span><br></pre></td></tr></table></figure></p>
<p>可以看到会输出很多<code>INFO</code> 开头的信息，这里我将所有的输出都写下来，虽然内容很多，有些没有必要看，但我觉得如果仔细看这些输出的话，很能增加对Spark的理解，所以这里我还是不厌其烦地把所有输出信息都列出来了。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties</span><br><span class="line">16/05/16 21:33:56 INFO SparkContext: Running Spark version 1.6.1</span><br><span class="line">16/05/16 21:33:56 WARN NativeCodeLoader: Unable to <span class="operator"><span class="keyword">load</span> <span class="keyword">native</span>-hadoop <span class="keyword">library</span> <span class="keyword">for</span> your platform... <span class="keyword">using</span> builtin-<span class="keyword">java</span> classes <span class="keyword">where</span> applicable</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">56</span> WARN Utils: Your hostname, ustc resolves <span class="keyword">to</span> a loopback address: <span class="number">127.0</span><span class="number">.1</span><span class="number">.1</span>;</span> using 192.168.102.77 instead (on interface eth0)</span><br><span class="line">16/05/16 21:33:56 WARN Utils: <span class="operator"><span class="keyword">Set</span> SPARK_LOCAL_IP <span class="keyword">if</span> you need <span class="keyword">to</span> bind <span class="keyword">to</span> another address</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">56</span> INFO SecurityManager: Changing <span class="keyword">view</span> acls <span class="keyword">to</span>: yunfeng</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">56</span> INFO SecurityManager: Changing <span class="keyword">modify</span> acls <span class="keyword">to</span>: yunfeng</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">56</span> INFO SecurityManager: SecurityManager: <span class="keyword">authentication</span> disabled;</span> ui acls disabled; users with view permissions: <span class="operator"><span class="keyword">Set</span>(yunfeng);</span> u</span><br><span class="line">sers with modify permissions: <span class="operator"><span class="keyword">Set</span>(yunfeng)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">56</span> INFO Utils: Successfully started service <span class="string">'sparkDriver'</span> <span class="keyword">on</span> port <span class="number">53174.</span></span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">56</span> INFO Slf4jLogger: Slf4jLogger started</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">56</span> INFO Remoting: <span class="keyword">Starting</span> remoting</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">56</span> INFO Remoting: Remoting started;</span> listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.102.77:57025]</span><br><span class="line">16/05/16 21:33:56 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 57025.</span><br><span class="line">16/05/16 21:33:56 INFO SparkEnv: Registering MapOutputTracker</span><br><span class="line">16/05/16 21:33:57 INFO SparkEnv: Registering BlockManagerMaster</span><br><span class="line">16/05/16 21:33:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2ace648a-937b-4a4c-b984-6e4cd06b8273</span><br><span class="line">16/05/16 21:33:57 INFO MemoryStore: MemoryStore started with capacity 511.5 MB</span><br><span class="line">16/05/16 21:33:57 INFO SparkEnv: Registering OutputCommitCoordinator</span><br><span class="line">16/05/16 21:33:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.</span><br><span class="line">16/05/16 21:33:57 INFO SparkUI: Started SparkUI at http://192.168.102.77:4040</span><br><span class="line">16/05/16 21:33:57 INFO Utils: Copying /home/yunfeng/Downloads/spark-1.6.1-bin-hadoop2.6/calc_pi.py to /tmp/spark-6cb08b18-143f-42dc-88c3-2778646</span><br><span class="line">0836b/userFiles-ae0a9fc0-65cf-467e-848b-4f3cf4e6e1c2/calc_pi.py</span><br><span class="line">16/05/16 21:33:57 INFO SparkContext: Added file file:/home/yunfeng/Downloads/spark-1.6.1-bin-hadoop2.6/calc_pi.py at file:/home/yunfeng/Download</span><br><span class="line">s/spark-1.6.1-bin-hadoop2.6/calc_pi.py with timestamp 1463405637243</span><br><span class="line">16/05/16 21:33:57 INFO Executor: Starting executor ID driver on host localhost</span><br><span class="line">16/05/16 21:33:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43770.</span><br><span class="line">16/05/16 21:33:57 INFO NettyBlockTransferService: Server created on 43770</span><br><span class="line">16/05/16 21:33:57 INFO BlockManagerMaster: Trying to register BlockManager</span><br><span class="line">16/05/16 21:33:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43770 with 511.5 MB RAM, BlockManagerId(driver, localhost</span><br><span class="line">, 43770)</span><br><span class="line">16/05/16 21:33:57 INFO BlockManagerMaster: Registered BlockManager</span><br><span class="line">16/05/16 21:33:57 INFO SparkContext: Starting job: reduce at /home/yunfeng/Downloads/spark-1.6.1-bin-hadoop2.6/calc_pi.py:12</span><br><span class="line">16/05/16 21:33:57 INFO DAGScheduler: Got job 0 (reduce at /home/yunfeng/Downloads/spark-1.6.1-bin-hadoop2.6/calc_pi.py:12) with 8 output partiti</span><br><span class="line">ons</span><br><span class="line">16/05/16 21:33:57 INFO DAGScheduler: Final stage: ResultStage 0 (reduce at /home/yunfeng/Downloads/spark-1.6.1-bin-hadoop2.6/calc_pi.py:12)</span><br><span class="line">16/05/16 21:33:57 INFO DAGScheduler: Parents of final stage: List()</span><br><span class="line">16/05/16 21:33:57 INFO DAGScheduler: Missing parents: List()</span><br><span class="line">16/05/16 21:33:57 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[1] at reduce at /home/yunfeng/Downloads/spark-1.6.1-bin-hadoop2.6/calc_</span><br><span class="line">pi.py:12), which has no missing parents</span><br><span class="line">16/05/16 21:33:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.3 KB, free 4.3 KB)</span><br><span class="line">16/05/16 21:33:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.8 KB, free 7.1 KB)</span><br><span class="line">16/05/16 21:33:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43770 (size: 2.8 KB, free: 511.5 MB)</span><br><span class="line">16/05/16 21:33:57 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006</span><br><span class="line">16/05/16 21:33:57 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 0 (PythonRDD[1] at reduce at /home/yunfeng/Downloads/spark-1.6.</span><br><span class="line">1-bin-hadoop2.6/calc_pi.py:12)</span><br><span class="line">16/05/16 21:33:57 INFO TaskSchedulerImpl: Adding task <span class="operator"><span class="keyword">set</span> <span class="number">0.0</span> <span class="keyword">with</span> <span class="number">8</span> tasks</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> WARN TaskSetManager: Stage <span class="number">0</span> contains a task <span class="keyword">of</span> very <span class="keyword">large</span> <span class="keyword">size</span> (<span class="number">486</span> KB). The maximum recommended task <span class="keyword">size</span> <span class="keyword">is</span> <span class="number">100</span> KB.</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO TaskSetManager: <span class="keyword">Starting</span> task <span class="number">0.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">0</span>, localhost, <span class="keyword">partition</span> <span class="number">0</span>,PROCESS_LOCAL, <span class="number">497894</span> <span class="keyword">bytes</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO TaskSetManager: <span class="keyword">Starting</span> task <span class="number">1.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">1</span>, localhost, <span class="keyword">partition</span> <span class="number">1</span>,PROCESS_LOCAL, <span class="number">629219</span> <span class="keyword">bytes</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO TaskSetManager: <span class="keyword">Starting</span> task <span class="number">2.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">2</span>, localhost, <span class="keyword">partition</span> <span class="number">2</span>,PROCESS_LOCAL, <span class="number">629219</span> <span class="keyword">bytes</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO TaskSetManager: <span class="keyword">Starting</span> task <span class="number">3.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">3</span>, localhost, <span class="keyword">partition</span> <span class="number">3</span>,PROCESS_LOCAL, <span class="number">629219</span> <span class="keyword">bytes</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO TaskSetManager: <span class="keyword">Starting</span> task <span class="number">4.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">4</span>, localhost, <span class="keyword">partition</span> <span class="number">4</span>,PROCESS_LOCAL, <span class="number">629219</span> <span class="keyword">bytes</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO TaskSetManager: <span class="keyword">Starting</span> task <span class="number">5.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">5</span>, localhost, <span class="keyword">partition</span> <span class="number">5</span>,PROCESS_LOCAL, <span class="number">629219</span> <span class="keyword">bytes</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO TaskSetManager: <span class="keyword">Starting</span> task <span class="number">6.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">6</span>, localhost, <span class="keyword">partition</span> <span class="number">6</span>,PROCESS_LOCAL, <span class="number">629219</span> <span class="keyword">bytes</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO TaskSetManager: <span class="keyword">Starting</span> task <span class="number">7.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">7</span>, localhost, <span class="keyword">partition</span> <span class="number">7</span>,PROCESS_LOCAL, <span class="number">632117</span> <span class="keyword">bytes</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO Executor: Running task <span class="number">3.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">3</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO Executor: Running task <span class="number">1.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">1</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO Executor: Running task <span class="number">0.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">0</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO Executor: Running task <span class="number">6.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">6</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO Executor: Running task <span class="number">7.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">7</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO Executor: Running task <span class="number">2.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">2</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO Executor: Running task <span class="number">5.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">5</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO Executor: Running task <span class="number">4.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">4</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO Executor: Fetching <span class="keyword">file</span>:/home/yunfeng/Downloads/spark-<span class="number">1.6</span><span class="number">.1</span>-<span class="keyword">bin</span>-hadoop2<span class="number">.6</span>/calc_pi.py <span class="keyword">with</span> <span class="keyword">timestamp</span> <span class="number">1463405637243</span></span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">57</span> INFO Utils: /home/yunfeng/Downloads/spark-<span class="number">1.6</span><span class="number">.1</span>-<span class="keyword">bin</span>-hadoop2<span class="number">.6</span>/calc_pi.py has been previously copied <span class="keyword">to</span> /tmp/spark-<span class="number">6</span>cb08b18-<span class="number">143</span></span><br><span class="line"><span class="keyword">f</span>-<span class="number">42</span>dc-<span class="number">88</span>c3-<span class="number">27786460836</span>b/userFiles-ae0a9fc0-<span class="number">65</span>cf-<span class="number">467e-848</span>b-<span class="number">4</span>f3cf4e6e1c2/calc_pi.py</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO PythonRunner: Times: total = <span class="number">340</span>, boot = <span class="number">226</span>, init = <span class="number">1</span>, <span class="keyword">finish</span> = <span class="number">113</span></span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO Executor: Finished task <span class="number">7.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">7</span>). <span class="number">998</span> <span class="keyword">bytes</span> <span class="keyword">result</span> sent <span class="keyword">to</span> driver</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO PythonRunner: Times: total = <span class="number">353</span>, boot = <span class="number">222</span>, init = <span class="number">2</span>, <span class="keyword">finish</span> = <span class="number">129</span></span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO PythonRunner: Times: total = <span class="number">359</span>, boot = <span class="number">230</span>, init = <span class="number">1</span>, <span class="keyword">finish</span> = <span class="number">128</span></span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO PythonRunner: Times: total = <span class="number">360</span>, boot = <span class="number">225</span>, init = <span class="number">3</span>, <span class="keyword">finish</span> = <span class="number">132</span></span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO PythonRunner: Times: total = <span class="number">358</span>, boot = <span class="number">224</span>, init = <span class="number">1</span>, <span class="keyword">finish</span> = <span class="number">133</span></span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO Executor: Finished task <span class="number">5.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">5</span>). <span class="number">998</span> <span class="keyword">bytes</span> <span class="keyword">result</span> sent <span class="keyword">to</span> driver</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO Executor: Finished task <span class="number">4.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">4</span>). <span class="number">998</span> <span class="keyword">bytes</span> <span class="keyword">result</span> sent <span class="keyword">to</span> driver</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO Executor: Finished task <span class="number">0.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">0</span>). <span class="number">998</span> <span class="keyword">bytes</span> <span class="keyword">result</span> sent <span class="keyword">to</span> driver</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO PythonRunner: Times: total = <span class="number">373</span>, boot = <span class="number">248</span>, init = <span class="number">0</span>, <span class="keyword">finish</span> = <span class="number">125</span></span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO Executor: Finished task <span class="number">1.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">1</span>). <span class="number">998</span> <span class="keyword">bytes</span> <span class="keyword">result</span> sent <span class="keyword">to</span> driver</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO Executor: Finished task <span class="number">2.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">2</span>). <span class="number">998</span> <span class="keyword">bytes</span> <span class="keyword">result</span> sent <span class="keyword">to</span> driver</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO TaskSetManager: Finished task <span class="number">7.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">7</span>) <span class="keyword">in</span> <span class="number">420</span> ms <span class="keyword">on</span> localhost (<span class="number">1</span>/<span class="number">8</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO TaskSetManager: Finished task <span class="number">5.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">5</span>) <span class="keyword">in</span> <span class="number">427</span> ms <span class="keyword">on</span> localhost (<span class="number">2</span>/<span class="number">8</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO PythonRunner: Times: total = <span class="number">385</span>, boot = <span class="number">245</span>, init = <span class="number">0</span>, <span class="keyword">finish</span> = <span class="number">140</span></span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO Executor: Finished task <span class="number">6.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">6</span>). <span class="number">998</span> <span class="keyword">bytes</span> <span class="keyword">result</span> sent <span class="keyword">to</span> driver</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO TaskSetManager: Finished task <span class="number">4.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">4</span>) <span class="keyword">in</span> <span class="number">431</span> ms <span class="keyword">on</span> localhost (<span class="number">3</span>/<span class="number">8</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO TaskSetManager: Finished task <span class="number">1.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">1</span>) <span class="keyword">in</span> <span class="number">439</span> ms <span class="keyword">on</span> localhost (<span class="number">4</span>/<span class="number">8</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO TaskSetManager: Finished task <span class="number">2.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">2</span>) <span class="keyword">in</span> <span class="number">437</span> ms <span class="keyword">on</span> localhost (<span class="number">5</span>/<span class="number">8</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO TaskSetManager: Finished task <span class="number">6.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">6</span>) <span class="keyword">in</span> <span class="number">430</span> ms <span class="keyword">on</span> localhost (<span class="number">6</span>/<span class="number">8</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO TaskSetManager: Finished task <span class="number">0.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">0</span>) <span class="keyword">in</span> <span class="number">455</span> ms <span class="keyword">on</span> localhost (<span class="number">7</span>/<span class="number">8</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO PythonRunner: Times: total = <span class="number">390</span>, boot = <span class="number">246</span>, init = <span class="number">1</span>, <span class="keyword">finish</span> = <span class="number">143</span></span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO Executor: Finished task <span class="number">3.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">3</span>). <span class="number">998</span> <span class="keyword">bytes</span> <span class="keyword">result</span> sent <span class="keyword">to</span> driver</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO TaskSetManager: Finished task <span class="number">3.0</span> <span class="keyword">in</span> stage <span class="number">0.0</span> (TID <span class="number">3</span>) <span class="keyword">in</span> <span class="number">442</span> ms <span class="keyword">on</span> localhost (<span class="number">8</span>/<span class="number">8</span>)</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO DAGScheduler: ResultStage <span class="number">0</span> (reduce <span class="keyword">at</span> /home/yunfeng/Downloads/spark-<span class="number">1.6</span><span class="number">.1</span>-<span class="keyword">bin</span>-hadoop2<span class="number">.6</span>/calc_pi.py:<span class="number">12</span>) finished <span class="keyword">in</span> <span class="number">0.467</span></span><br><span class="line"> s</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO TaskSchedulerImpl: Removed TaskSet <span class="number">0.0</span>, whose tasks have all completed, <span class="keyword">from</span> pool </span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO DAGScheduler: Job <span class="number">0</span> finished: reduce <span class="keyword">at</span> /home/yunfeng/Downloads/spark-<span class="number">1.6</span><span class="number">.1</span>-<span class="keyword">bin</span>-hadoop2<span class="number">.6</span>/calc_pi.py:<span class="number">12</span>, took <span class="number">0.569039</span> s</span><br><span class="line">*****<span class="keyword">result</span>:<span class="keyword">pi</span> <span class="keyword">is</span> :<span class="number">3.140324</span>*****</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO SparkContext: Invoking <span class="keyword">stop</span>() <span class="keyword">from</span> <span class="keyword">shutdown</span> hook</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO SparkUI: Stopped Spark web UI <span class="keyword">at</span> <span class="keyword">http</span>://<span class="number">192.168</span><span class="number">.102</span><span class="number">.77</span>:<span class="number">4040</span></span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO MemoryStore: MemoryStore cleared</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO BlockManager: BlockManager stopped</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO BlockManagerMaster: BlockManagerMaster stopped</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO SparkContext: Successfully stopped SparkContext</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO ShutdownHookManager: <span class="keyword">Shutdown</span> hook called</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO ShutdownHookManager: Deleting <span class="keyword">directory</span> /tmp/spark-<span class="number">6</span>cb08b18-<span class="number">143</span><span class="keyword">f</span>-<span class="number">42</span>dc-<span class="number">88</span>c3-<span class="number">27786460836</span>b/pyspark-<span class="number">33</span>d22309-ef12-<span class="number">45</span>d6-<span class="number">9862</span>-<span class="number">2</span></span><br><span class="line"><span class="number">5</span>ceb8beadac</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO ShutdownHookManager: Deleting <span class="keyword">directory</span> /tmp/spark-<span class="number">6</span>cb08b18-<span class="number">143</span><span class="keyword">f</span>-<span class="number">42</span>dc-<span class="number">88</span>c3-<span class="number">27786460836</span>b</span><br><span class="line"><span class="number">16</span>/<span class="number">05</span>/<span class="number">16</span> <span class="number">21</span>:<span class="number">33</span>:<span class="number">58</span> INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.</span></span><br></pre></td></tr></table></figure></p>
<p>可以看到在96行，输出了我们想要的结果：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*****result:pi is :<span class="number">3.140324</span>*****</span><br></pre></td></tr></table></figure></p>
<p>需要注意的是：Spark自动在本地开了8个进程，来模拟在分布式情况下的计算节点，这样就可以在单机情况下调试适用于分布式情况下的代码了。  </p>
<h3 id="5-_在分布式环境下部署">5. 在分布式环境下部署</h3><p>在单机上调试好程序后，我们就可以将代码部署到分布式的机器上了。<strong>这里有个要求：每个分布式的机器节点上都必须安装相同版本的Spark。</strong>所以第一步就是再各个机器上安装Spark。  </p>
<p>安装完Spark后，我们就可以通过下面的命令来启动各个节点的Spark了：<br>1.在要运行Driver程序（master）的机器上，在Spark根目录下，执行命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sbin/start-master.sh</span><br></pre></td></tr></table></figure></p>
<p>2.在<strong>各个Worker Node上</strong>，连接到主节点上：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sbin/star-slave.sh &lt;master-spark-URL&gt;</span><br></pre></td></tr></table></figure></p>
<p>这是一种手动启动的方式。此外，还可以通过在Driver 程序所在节点上执行下面的命令来自动地启动或停止所有节点的Spark程序：</p>
<ul>
<li><code>sbin/start-master.sh</code> ： 启动主进程 </li>
<li><code>sbin/start-slaves.sh</code> ： 启动<code>conf/slaves</code>文件里面的所有节点</li>
<li><code>sbin/start-all.sh</code> ： 启动主进程和所有计算节点</li>
<li><code>sbin/stop-master.sh</code>： 停止主进程</li>
<li><code>sbin/stop-slavers.sh</code> ： 停止所有计算节点</li>
</ul>
<p>配置完分布式环境后，就可以运行程序了。以上述的<code>calc_pi.py</code>为例，假设master程序运行在192.168.3.2:8080，则在运行master的主机上运行如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit -master spark://<span class="number">192.168</span>.<span class="number">3.2</span>:<span class="number">8080</span> calc_pi.py</span><br></pre></td></tr></table></figure></p>
<p>这样就可以分布式地运行Spark了！</p>
<p>至此Spark的内容的总结就结束了，总的来说，Spark编程并没有想象中的那么复杂，恰恰相反，随着时间的推移，这些开发工具越来越对开发者友好，这也是使得Spark能轻易地上手的原因。  </p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="概述">概述</h2><p>这篇文章是我通过学习了Spark官网上的一些内容，参考了许多博客和文章，也尝试进行了一些初级的Spark编程后写的关于Spark的简要的说明，希望能讲明白Spark这个框架的一些原理，提供一个基础的入门教程。  </p>
<p><img src="http://spark.apache.org/images/spark-logo-trademark.png" alt="Spark logo">    </p>]]>
    
    </summary>
    
      <category term="Python" scheme="http://vra.github.io/tags/Python/"/>
    
      <category term="Spark" scheme="http://vra.github.io/tags/Spark/"/>
    
      <category term="并行计算" scheme="http://vra.github.io/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[caffe compilation troubleshooting]]></title>
    <link href="http://vra.github.io/2016/04/13/caffe-compile/"/>
    <id>http://vra.github.io/2016/04/13/caffe-compile/</id>
    <published>2016-04-13T10:45:47.000Z</published>
    <updated>2017-01-08T09:23:44.618Z</updated>
    <content type="html"><![CDATA[<h2 id="Issue_1">Issue 1</h2><p>When I compile caffe toolkit(actually, a caffe fork: lisa-caffe-public), I always encounter some errors like:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Tab found; better use space</span><br><span class="line">Line should be &lt;= <span class="number">80</span> characters</span><br><span class="line">Missing space before ( <span class="keyword">in</span> <span class="keyword">if</span>(</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>At the beginning, I thought these warnings  were caused by gcc/g++, so I googled but found few result about this question.<br>Then I read the manual of gcc. In the manual, I found some useful information:</p>
<ol>
<li>Adding <code>-Wall</code> parameter after <code>gcc</code> will display all warning information.</li>
<li>Adding <code>-w</code> parameter will turn off all warning information.    </li>
<li>Adding <code>-Wstring</code> will display warning information about <code>string</code>.  For example, if <code>-Wfloat-equal</code> is set, then it will warn if floating-point values are used in equality comparisons.</li>
<li>Adding <code>-Wno-string</code> will not display warning information about <code>string</code>. For example, if <code>-Wno-div-by-zero</code>, then it will not warn if integer division by zero.</li>
</ol>
<p>So I try to review Makefile of caffe and comment some lines, but the warning information remain. The knowledge is useful, but can’t solve my problem.<br>After searching and searching, I finally found that it’s <a href="https://github.com/google/styleguide/tree/gh-pages/cpplint" target="_blank" rel="external">cpplint</a> that caused errors. Cpplint is automated checker to make sure a C++ file follows Google’s C++ style guide. So I checked the Makefile, and find a line like this:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EVERYTHING_TARGETS := all py$(PROJECT) <span class="built_in">test</span> warn lint</span><br></pre></td></tr></table></figure></p>
<p>Explain: <code>EVERYTHING_TARGETS</code> is target of command <code>make everything</code>. When compile caffe, we can just type <code>make everything</code> then gcc will do everything for us, including <code>make all</code>, <code>make test</code>, <code>make warn</code>, <code>make lint</code>.<br>So finally I got the simplest solution: just remove <code>lint</code> from this line and recompiled it. This time everything went well.</p>
<h2 id="Issue_2">Issue 2</h2><p>When I train network using lisa-caffe-public, I encounter error:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Unknown layer <span class="built_in">type</span>: Python</span><br></pre></td></tr></table></figure></p>
<p>I searched about this question and found the answer <a href="https://github.com/rbgirshick/fast-rcnn/issues/31" target="_blank" rel="external">here</a>: <strong>uncomment WITH__PYTHON_LAYER: =1 in Makefile.config and recompile it.</strong><br>lisa-caffe-public is a fork of fast-rcnn, which is a fork of original caffe of BVLC. The developer of fast-rcnn use <code>Python layer</code> in his implementation and lisa’s caffe fork inherits it. In order to run the network correctly, we must use the flag when compiling the source code.  </p>
<h2 id="Issue_3">Issue 3</h2><p>Error message like this:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fatal error: caffe/proto/caffe.pb.h: No such file or directory</span><br></pre></td></tr></table></figure></p>
<p>caffe.pb.h is a header file generated by Google Protocol Buffer. <a href="https://www.ibm.com/developerworks/cn/linux/l-cn-gpb/" target="_blank" rel="external">Here</a> is a tutorial about it.  We must first generate it use commands below:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ protoc src/caffe/proto/caffe.proto --cpp_out=.</span><br><span class="line">$ mkdir include/caffe/proto</span><br><span class="line">$ mv src/caffe/proto/caffe.pb.h include/caffe/proto</span><br></pre></td></tr></table></figure></p>
<p>Then compile again and we have the question solved.<br>Reference from <a href="https://github.com/NVIDIA/DIGITS/issues/105" target="_blank" rel="external">here</a></p>
<h2 id="Issue_4">Issue 4</h2><p>Error message like this:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Check failed: proto.SerializeToOstream(&amp;output)</span><br></pre></td></tr></table></figure></p>
<p>This error happens when write snapshot to disk. There are three reasons that cause this error:</p>
<ol>
<li>The writing directory doesn’t exist</li>
<li>You have to permission to write in the directory</li>
<li>The target disk is full </li>
</ol>
<p>You can check these 3 aspects.<br>Reference: <a href="https://github.com/BVLC/caffe/issues/1394" target="_blank" rel="external">https://github.com/BVLC/caffe/issues/1394</a></p>
<h2 id="Issue_5">Issue 5</h2><p>When use <a href="https://github.com/rbgirshick/fast-rcnn" target="_blank" rel="external">fast R-CNN</a>, got error like this:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Floating point exception(core dumped).</span><br></pre></td></tr></table></figure></p>
<p>It’s like something about box size. the solution is add <code>filter_roidb</code> function in <code>lib/fast_rcnn/train.py</code> file, like <a href="https://github.com/rbgirshick/py-faster-rcnn/blob/d66cc2bff142ca07f521db06ca3e9e10dbc8df20/lib/fast_rcnn/train.py#L127" target="_blank" rel="external">here</a>.<br>Reference: <a href="https://github.com/rbgirshick/py-faster-rcnn/issues/159" target="_blank" rel="external">https://github.com/rbgirshick/py-faster-rcnn/issues/159</a></p>
<h2 id="Issue_6">Issue 6</h2>]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Issue_1">Issue 1</h2><p>When I compile caffe toolkit(actually, a caffe fork: lisa-caffe-public), I always encounter some errors like:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Tab found; better use space</span><br><span class="line">Line should be &lt;= <span class="number">80</span> characters</span><br><span class="line">Missing space before ( <span class="keyword">in</span> <span class="keyword">if</span>(</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Caffe" scheme="http://vra.github.io/tags/Caffe/"/>
    
      <category term="Deep Learning" scheme="http://vra.github.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[A Simple Introduction to Make]]></title>
    <link href="http://vra.github.io/2016/04/10/make-introduction/"/>
    <id>http://vra.github.io/2016/04/10/make-introduction/</id>
    <published>2016-04-10T15:11:55.000Z</published>
    <updated>2017-01-08T09:23:44.634Z</updated>
    <content type="html"><![CDATA[<p>GNU Make is a tool which controls the generation of executables and other non-source files of a program from the program’s source files.<br>Make gets its knowledge of how to build your program from a file called the makefile, which lists each of the non-source files and how to compute it from other files. When you write a program, you should write a makefile for it, so that it is possible to use Make to build and install the program.<br>I will introduce some basic skills about using make.<br><a id="more"></a></p>
<h2 id="Format_of_make">Format of make</h2><p>The format of make rule is:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">target: prerequisite</span><br><span class="line">	<span class="built_in">command</span></span><br></pre></td></tr></table></figure></p>
<p><code>target</code> is the output or middle objects. <code>prerequisite</code> is the requiring files for target. When <code>prerequisite</code> files have update, then when you execute <code>make</code> command, the utility will generate target. the <code>command</code> indicates how to generate <code>target</code>. <code>command</code> can be any shell commands. But generally, <code>commmand</code> contains the compiling commands. A example of make command:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file: file.c file.h</span><br><span class="line">	gcc -o file file.c file.h</span><br></pre></td></tr></table></figure></p>
<p>There can be many targets in make file, but the first target will be executed when type <code>make</code>.</p>
<h2 id="Define_variables">Define variables</h2><p>We can define variables and use it in Makefile. for example:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">OBJ = file.o</span><br><span class="line">file: $(OBJ)</span><br><span class="line">	gcc -o file $(OBJ)</span><br><span class="line">$(OBJ): file.c file.h</span><br><span class="line">	gcc -c file.c file.h</span><br></pre></td></tr></table></figure></p>
<p>In this example, we define <code>OBJ</code> as <code>file.o</code> and use it later to replace <code>file.o</code>.<br>It can be quite useful if there are many objects files in target or prerequisite.<br>Sometimes we can move object files or head files to other directories, at this time, we can define variables to reduce our typing. For example, you have <code>*.h</code> file in <code>lib</code> directory in current path, you can write like this:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LIB = lib</span><br><span class="line">file: file.c $(LIB)/file.h</span><br><span class="line">	gcc -o file file.c $(LIB)/file.h</span><br></pre></td></tr></table></figure></p>
<h2 id="Phony_target">Phony target</h2><p>Phony target is a kind of label in make. It’s similar to target, but it has no prerequisite for most time, and we can append it to <code>make</code> command to execute command defined in it. For example:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.PHONY: clean</span><br><span class="line">clean: </span><br><span class="line">	rm *.o file</span><br></pre></td></tr></table></figure></p>
<p>When we type <code>make clean</code> in command line, <code>rm *.o file</code> will be executed.<br>NOTE: in order to avoid phony target has the same name with file in directory, we add <code>.PHONY clean</code> to make sure that clean command must be executed.<br>Sometimes phony target can have prerequisite, and place it as the first target, then this phony target will be execute. This is very helpful when you want generate several executable files and you just want type a <code>make</code>. For example:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">all: prog1 prog2 prog3  </span><br><span class="line">.PHONY: all  </span><br><span class="line">  </span><br><span class="line">prog1: prog1.o utils.o  </span><br><span class="line">	cc -o prog1 prog1.o utils.o  </span><br><span class="line">  </span><br><span class="line">prog2: prog2.o  </span><br><span class="line">	cc -o prog2 prog2.o  </span><br><span class="line">  </span><br><span class="line">prog3: prog3.o sort.o utils.o  </span><br><span class="line">	cc -o prog3 prog3.o sort.o utils.o</span><br></pre></td></tr></table></figure></p>
<h2 id="Automatic_variables">Automatic variables</h2><p>There are some default variables in each make rule. We can use it to simplify our work. There are some useful automatic variables:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$@</span>: The file name of the target of the rule</span><br><span class="line">$%: The target member name, when the target is an archive member</span><br><span class="line">$&lt;: The name of the first prerequisite</span><br><span class="line">$?: The names of all the prerequisites that are newer than the target, with spaces between them</span><br><span class="line">$^: The names of all the prerequisites, with spaces between them</span><br></pre></td></tr></table></figure></p>
<p>For example, if we have a makefile like this:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CC=gcc</span><br><span class="line">CFLAG=I.</span><br><span class="line">DEPS=hellomake.h</span><br><span class="line"></span><br><span class="line">%.o: %.c $(DEPS)</span><br><span class="line">	$(CC) -c -o <span class="variable">$@</span> $&lt; $(CFLAG)</span><br></pre></td></tr></table></figure></p>
<p>Where <code>$@</code> indicates the <code>.o</code> file and <code>@&lt;</code> indicates the corresponding <code>.c</code> file.</p>
<h2 id="Other_skills">Other skills</h2><ol>
<li>comments begin with <code>#</code>, just like shell</li>
<li><p>the comment begin with <code>@</code> will not be display, so we can echo like this:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@<span class="built_in">echo</span> <span class="string">'Compiling begin...'</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>We can choose make file using <code>-f</code> options: <code>make -f myMakefile</code> will choose <code>myMakefile</code> as rule file.</p>
</li>
<li>Adding <code>-n</code> in make will not do make really, just test if all things are okay.</li>
<li>We can use <code>include</code> to add other makefiles into here, for example: <code>include Makefile1 Makefile2</code>.</li>
<li>Add <code>-</code> in front of a command will ignore the errors occurring when execute it. </li>
</ol>
<h2 id="Reference:">Reference:</h2><ol>
<li><a href="https://www.gnu.org/software/make/manual/html_node/" target="_blank" rel="external">https://www.gnu.org/software/make/manual/html_node/</a></li>
<li><a href="http://blog.csdn.net/haoel/article/details/2886" target="_blank" rel="external">http://blog.csdn.net/haoel/article/details/2886</a></li>
<li><a href="http://www.cs.colby.edu/maxwell/courses/tutorials/maketutor/" target="_blank" rel="external">http://www.cs.colby.edu/maxwell/courses/tutorials/maketutor/</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>GNU Make is a tool which controls the generation of executables and other non-source files of a program from the program’s source files.<br>Make gets its knowledge of how to build your program from a file called the makefile, which lists each of the non-source files and how to compute it from other files. When you write a program, you should write a makefile for it, so that it is possible to use Make to build and install the program.<br>I will introduce some basic skills about using make.<br>]]>
    
    </summary>
    
      <category term="Linux" scheme="http://vra.github.io/tags/Linux/"/>
    
      <category term="Make" scheme="http://vra.github.io/tags/Make/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[cool-certificate, 一个好玩的证书生成工具]]></title>
    <link href="http://vra.github.io/2016/04/07/cool-certificate/"/>
    <id>http://vra.github.io/2016/04/07/cool-certificate/</id>
    <published>2016-04-07T15:15:03.000Z</published>
    <updated>2017-01-08T09:23:44.734Z</updated>
    <content type="html"><![CDATA[<p>前几天同学发过来一张无人机驾驶证的照片，瞬间觉得很高大上，仔细一询问，原来是用软件生成的图片，网址是：<a href="http://wx.znl.cn/app/index.php?i=120&amp;c=entry&amp;id=1&amp;do=index&amp;m=bi_pic" target="_blank" rel="external">http://wx.znl.cn/app/index.php?i=120&amp;c=entry&amp;id=1&amp;do=index&amp;m=bi_pic</a>。 当访问该网站的时候，用户输入用户名，然后就生成包含用户名的驾照照片。我接着想能不能自己做一个类似这样的东西呢，经过思考发现，其实操作比较简单，即将用户姓名写入到图像上的合适位置即可。因为我之前已经有一些用Python 的Django框架做小的网站的经验，而且Python PIL模块可以完成这个任务，所以我立即想到， 能不能结合两者，建立一个网站，让用户输入姓名，然后将用户姓名传入到后台，后台调用PIL函数，将名字写到图片的相应位置上，然后返回给用户呢？经过思考我发现这种思路是可行的，而且工作量貌似也不是很大，所以今天早上开始做了做，在无人机驾照的基础上又增加了2个有趣的证件：潜水证和超级帅哥证，今晚终于作出了一个粗糙的结果（网站页面使用了原始和简单的HTML标签），可以在<a href="http://115.28.30.25:8001/" target="_blank" rel="external">这里</a>访问。代码已经上传到<a href="https://github.com/vra/cool_certificate" target="_blank" rel="external">github上</a>了。下面记下来实现过程中的一些思考。<br><a id="more"></a></p>
<h2 id="整体实现流程">整体实现流程</h2><ol>
<li>用Django实现网站前端和后端，展示页面给用户，读取用户输入</li>
<li>当用户输入后，利用POST方法返回用户名到服务器端</li>
<li>对特定的证件和已给的用户，利用PIL中的ImageFont模块来在证件照片的相应用户名空当处写上用户名,然后保存处理后的图片。用户名应该写在哪里需要手工确定（我用Windows 的画图工具中找到具体的位置坐标）</li>
<li>将生成的图片返回给网站页面</li>
</ol>
<h2 id="实现的一些细节问题">实现的一些细节问题</h2><h3 id="将文字写到图片上">将文字写到图片上</h3><p>这里使用PIL（Python Image Library）来做，利用了其中的ImageFont模块，核心的代码段如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(img_path)                                                                                                                                                   draw = ImageDraw.Draw(img)                                                                                                                                               </span><br><span class="line">   font = ImageFont.truetype(font_path, font_size)                                                                                                                          </span><br><span class="line">   <span class="comment">#<span class="doctag">NOTE:</span> django get parameter as unicode, so don't need to encode to unicode.                                                                                                  draw.text(word_pos, name, word_color, font=font)                                                                                                                         </span></span><br><span class="line">   img.save(out_img_path)</span><br></pre></td></tr></table></figure></p>
<p>One things you must notice is that Django return stirng in the unicode format, so you dont’t have to do <code>unicode(name, &#39;utf-8&#39;)</code> anymore.<br>用户输入姓名时，生成包含姓名的证件图片，保存在本地。<br>在实际操作中发现，有些字体不支持部分中文，所以我在网上下了<code>Aria Unicode</code>字体，经测试发现能显示所有中文字体。  </p>
<h3 id="Django返回处理图片的格式">Django返回处理图片的格式</h3><p>我最初想的是用户点击确定按钮后，跳转到新的页面，在这个页面上单独显示处理后的照片，所以response类型设置成<code>image/jpeg</code>即可。但实际操作中出现问题，只返回照片似乎有一些问题，所以我修改实现，在传给Template的时候，传递一个参数<code>done</code>, 如果当前没有增加用户姓名，则该值为0,否则为1。在Template中，如果值为0,则展示未处理的模板图片;如果值为1,则显示处理后的图片。</p>
<h3 id="静态文件目录的设置">静态文件目录的设置</h3><p>Django将CSS,JS和Image图片都看作静态文件，推荐在app目录下建立<code>static</code>目录来保存这些文件。这里需要进行一定的设置，将保存模板图片和生成图片的目录<code>imgs</code>增加到<code>static</code>目录下，设置代码如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># in settings.py</span></span><br><span class="line">SITE_ROOT = os.path.join(os.path.abspath(os.path.dirname(__file__)),<span class="string">''</span>)                                                                                                      </span><br><span class="line">STATIC_ROOT = os.path.join(SITE_ROOT,<span class="string">'static'</span>)                                                                                                                               </span><br><span class="line">STATIC_URL = <span class="string">'/static/'</span>                                                                                                                                                      </span><br><span class="line">                                                                                                                                                                             </span><br><span class="line"><span class="comment">#最后关键部分需要添加上STATICFILE_DIRS的配置                                                                                                                                 </span></span><br><span class="line">STATICFILES_DIRS = (                                                                                                                                                         </span><br><span class="line">    (<span class="string">"css"</span>, os.path.join(STATIC_ROOT,<span class="string">'css'</span>)),                                                                                                                                </span><br><span class="line">    (<span class="string">"js"</span>, os.path.join(STATIC_ROOT,<span class="string">'js'</span>)),                                                                                                                                  </span><br><span class="line">    (<span class="string">"imgs"</span>, os.path.join(STATIC_ROOT,<span class="string">'imgs'</span>)),                                                                                                                              </span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>经过这样设置，在调用<code>imgs</code>目录下的图片时就可以这样调用了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;img src = <span class="string">"&#123;% static "</span>imgs/feiji.jpg<span class="string">"%&#125;"</span>&gt;</span><br></pre></td></tr></table></figure></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>前几天同学发过来一张无人机驾驶证的照片，瞬间觉得很高大上，仔细一询问，原来是用软件生成的图片，网址是：<a href="http://wx.znl.cn/app/index.php?i=120&amp;c=entry&amp;id=1&amp;do=index&amp;m=bi_pic">http://wx.znl.cn/app/index.php?i=120&amp;c=entry&amp;id=1&amp;do=index&amp;m=bi_pic</a>。 当访问该网站的时候，用户输入用户名，然后就生成包含用户名的驾照照片。我接着想能不能自己做一个类似这样的东西呢，经过思考发现，其实操作比较简单，即将用户姓名写入到图像上的合适位置即可。因为我之前已经有一些用Python 的Django框架做小的网站的经验，而且Python PIL模块可以完成这个任务，所以我立即想到， 能不能结合两者，建立一个网站，让用户输入姓名，然后将用户姓名传入到后台，后台调用PIL函数，将名字写到图片的相应位置上，然后返回给用户呢？经过思考我发现这种思路是可行的，而且工作量貌似也不是很大，所以今天早上开始做了做，在无人机驾照的基础上又增加了2个有趣的证件：潜水证和超级帅哥证，今晚终于作出了一个粗糙的结果（网站页面使用了原始和简单的HTML标签），可以在<a href="http://115.28.30.25:8001/">这里</a>访问。代码已经上传到<a href="https://github.com/vra/cool_certificate">github上</a>了。下面记下来实现过程中的一些思考。<br>]]>
    
    </summary>
    
      <category term="PIL" scheme="http://vra.github.io/tags/PIL/"/>
    
      <category term="Python" scheme="http://vra.github.io/tags/Python/"/>
    
      <category term="图像处理" scheme="http://vra.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
      <category term="工具" scheme="http://vra.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[markdown易错点总结]]></title>
    <link href="http://vra.github.io/2016/03/29/markdown-note/"/>
    <id>http://vra.github.io/2016/03/29/markdown-note/</id>
    <published>2016-03-29T06:36:25.000Z</published>
    <updated>2017-01-08T09:23:44.606Z</updated>
    <content type="html"><![CDATA[<p>markdown 是一种标记语言，我这个博客就是用markdown格式写好后，由hexo框架将markdown格式转换为静态的HTML文件，再上传到网站服务器上。在使用markdown的时候，有的时候在使用有序列表的时候，总会出现一些与预期效果不符的情况。因此今天我查看了markdown的文档，发现有一些规则我之前没注意到，导致出错，所以写下来，避免再犯错了。<br><a id="more"></a></p>
<ol>
<li>有序下标中，有多个段落，则下标以及每个段落的开头都必须缩进4个空格或1个制表符<ol>
<li>how are you today?<br>I am fine.</li>
<li>Good Morning!<br>Good Morning!</li>
</ol>
</li>
<li><p>下标中的表示代码段的3个撇号不用缩进</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>不同下标间不用空行，否则也会出错</p>
</li>
<li><p>表示代码结束的三个```后面不能加空格，否则后面的内容也会被当作代码段的。</p>
</li>
<li><p><strong>在GitHub网站上，有序列表的不同下标之间需要隔一个空行，否则渲染会出问题</strong><br>参考:<a href="http://wowubuntu.com/markdown/" target="_blank" rel="external">http://wowubuntu.com/markdown/</a></p>
</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>markdown 是一种标记语言，我这个博客就是用markdown格式写好后，由hexo框架将markdown格式转换为静态的HTML文件，再上传到网站服务器上。在使用markdown的时候，有的时候在使用有序列表的时候，总会出现一些与预期效果不符的情况。因此今天我查看了markdown的文档，发现有一些规则我之前没注意到，导致出错，所以写下来，避免再犯错了。<br>]]>
    
    </summary>
    
      <category term="markdown" scheme="http://vra.github.io/tags/markdown/"/>
    
      <category term="总结" scheme="http://vra.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[C3D Usage Summary]]></title>
    <link href="http://vra.github.io/2016/03/03/c3d-use/"/>
    <id>http://vra.github.io/2016/03/03/c3d-use/</id>
    <published>2016-03-03T09:34:05.000Z</published>
    <updated>2017-01-08T09:23:44.618Z</updated>
    <content type="html"><![CDATA[<p><a href="https://github.com/facebook/C3D" target="_blank" rel="external">C3D</a> is a deep learning tool which is modified version of BVLC <a href="https://github.com/BVLC/caffe" target="_blank" rel="external">caffe</a> to support 3D convolution and pooling. it was released by Facebook. In the field of human action recognition, C3D feature of video clip is the state-of-the-art feature. In this blog, I write some notes for using this tool in practice.<br><a id="more"></a></p>
<h2 id="1-_Compile_C3D">1. Compile C3D</h2><ol>
<li><p>Clone C3D from github:</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">clone</span> <span class="title">https</span>://github.com/facebook/C3D.git</span><br></pre></td></tr></table></figure>
</li>
<li><p>Compile it:</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cp Makefile<span class="class">.config</span><span class="class">.example</span> Makefile<span class="class">.config</span></span><br><span class="line"><span class="hexcolor">#ada</span>pt makefile according to configuration of your machine, <span class="keyword">for</span> example, change atblas to mkl</span><br><span class="line">make all -j <span class="number">32</span></span><br></pre></td></tr></table></figure>
<p><code>-j 32</code> means use 32 cores to compile it in parallel.</p>
<p>When something goes wrong, search the Internet, find a solution and update your makefile.    </p>
</li>
<li><p>Test whether the compilation is finished correctly.  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#assume you are at C3D root directory right now  </span></span><br><span class="line"><span class="built_in">cd</span> examples/c3d_feature_extraction  </span><br><span class="line"><span class="comment">#download trained sport1m caffemodel from net  </span></span><br><span class="line">sh c3d_sport1m_feature_extraction_frm.sh</span><br></pre></td></tr></table></figure>
<p>  If the command above runs correctly, your compilation is successful!  </p>
</li>
</ol>
<h2 id="2-_Use_C3D_to_extract_feature_of_UCF101_video_dataset">2. Use C3D to extract feature of UCF101 video dataset</h2><ol>
<li><p>Get the dataset and write list files<br> First download UCF101 dataset from <a href="http://crcv.ucf.edu/data/UCF101.php" target="_blank" rel="external">http://crcv.ucf.edu/data/UCF101.php</a>, and then write list files.</p>
<p> Since C3D can read video clips and frames of videos, you can write input list file and output list file in both way.</p>
<p> For frame format, you need  to transform video to frames firstly, I use ffmpeg to do this job:</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -<span class="tag">i</span> <span class="string">"/path/to/video"</span> <span class="string">"/path/to/frm/dir/%06d.jpg"</span></span><br></pre></td></tr></table></figure>
<p> The input list file contains the paths to video clips or frames, the output list file contains the path where to save the features.</p>
<p> The format of input list file is like this:  </p>
<p> <code>&lt;string_path&gt; &lt;starting_frame&gt; &lt;label&gt;</code>  </p>
<p> for example, <code>/home/yunfeng/dataset/ucf101/ucf101_frm/YoYo/v_YoYo_g23_c01/ 1 100</code><br> <strong>NOTE: for video clip, <code>starting_frame</code> starts from 0, but for frames, it starts from 1.</strong>  </p>
<p> the format of output list file is like this:<br> <code>&lt;output_folder&gt;</code><br> for example, <code>/output/c3d/YoYo//v_YoYo_g23_c01/000001</code>  </p>
</li>
<li><p>Create output directory YOURSElF<br> <strong>NOTE: C3D does not create directories in output list file, you must create them yourself.</strong>  </p>
<p> There is a simple way: since we have path to target directory in output list file, we can use it:  </p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="id">#assume</span> you are at C3D root directory <span class="attribute">right</span> now</span><br><span class="line"><span class="number">1</span>. cd examples/c3d_feature_extraction</span><br><span class="line"><span class="number">2</span>. cp prototxt/output_list_prefix<span class="class">.txt</span> create_dir<span class="class">.sh</span></span><br><span class="line"><span class="number">3</span>. vi create_dir.sh</span><br></pre></td></tr></table></figure>
<p> In vi, do two steps to change diretories to shell commands:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">:0,$s/\/\d\+/\//g # remove the number at the <span class="operator"><span class="keyword">end</span> <span class="keyword">of</span> <span class="keyword">each</span> line.</span><br><span class="line">:<span class="number">0</span>,$s/<span class="keyword">output</span>/mkdir -<span class="keyword">p</span> <span class="keyword">output</span>/<span class="keyword">g</span> # <span class="keyword">add</span> <span class="string">`mkdir -p`</span> command <span class="keyword">at</span> the <span class="keyword">head</span> <span class="keyword">of</span> <span class="keyword">each</span> line.</span></span><br></pre></td></tr></table></figure>
<p> then run the command to create directories:</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sh</span> create_dir.<span class="keyword">sh</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Use tools to extract features<br>After finishing first step, you need to write a prototxt file. Fortunately, there is a example file in the directory: <code>prototxt/c3d_sport1m_feature_extractor_frm.prototxt</code>, you can adapt it to have right access to input list file.  </p>
<p>We use tool named <code>extract_image_features.bin</code> in <code>build/tools</code> directory to extract features, the usage of it is </p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> extract_image_features.bin <span class="tag">&lt;<span class="title">feature_extractor_prototxt_file</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="title">c3d_pre_trained_model</span>&gt;</span> <span class="tag">&lt;<span class="title">gpu_id</span>&gt;</span> <span class="tag">&lt;<span class="title">mini_batch_size</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="title">number_of_mini_batches</span>&gt;</span> <span class="tag">&lt;<span class="title">output_prefix_file</span>&gt;</span> <span class="tag">&lt;<span class="title">feature_name1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">feature_name2</span>&gt;</span> ...</span><br></pre></td></tr></table></figure>
<p>We can use command below to extract feature:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GLOG_logtosterr=<span class="number">1</span> ../../build/tools/extract_image_features.bin</span><br><span class="line">prototxt/c3d_sport1m_feature_extractor_frm.prototxt </span><br><span class="line">conv3d_deepnetA_sport1m_iter_1900000 <span class="number">0</span> <span class="number">50</span> <span class="number">1</span> </span><br><span class="line">prototxt/output_list_prefix.txt fc7­<span class="number">1</span> fc6­<span class="number">1</span> prob</span><br></pre></td></tr></table></figure>
<p>After extraction of feature, we can use matlab code in <code>script</code> subdirectory of <code>example/c3d_feature_extraction</code> to do further job. There are two matlab files in <code>script</code>, <code>read_binary_blob.m</code>, <code>read_binary_blob_preserve_shape.m</code>. There are used to transform features into binary blob data, We can use these two functions for further analysis of features.</p>
</li>
</ol>
<h2 id="3-_Train_3D_convolution_neural_network">3. Train 3D convolution neural network</h2><p>Since C3D is a fork of <a href="http://github.com/bvlc/caffe.git" target="_blank" rel="external">Caffe</a>, which is a fast open framework for deep learning, We can use C3D to train deep networks. You can train from scratch or fine-tune C3D on your own dataset.</p>
<ol>
<li><p>Train from scratch</p>
<p>C3D offers some useful shell scripts to simplify our job, we can read the scripts and adapt it according our tasks.</p>
<p><strong>NOTE: you must adapt the shell scripts to ensure that every parameter is correct for your task!</strong></p>
<p>the schedule of training from scratch is(assuming we are training on ucf101):</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#assume you are at C3D root directory right now</span></span><br><span class="line"><span class="number">1</span>. <span class="built_in">cd</span> examples/c3d_train_ucf101</span><br><span class="line"><span class="number">2</span>. sh create_volume_means.sh <span class="comment"># compute the mean file of your dataset</span></span><br><span class="line"><span class="number">3</span>. sh train_ucf101.sh <span class="comment"># train from scratch </span></span><br><span class="line"><span class="number">4</span>. <span class="built_in">test</span>_ucf101.sh <span class="comment"># test the accuracy of training</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Fine-Tune on C3D</p>
<p> First you have to download pretrained model, then you can do fine-tuning like this:</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#assume you are at C3D root directory <span class="keyword">right</span> now</span><br><span class="line"><span class="number">1</span>. <span class="keyword">cd</span> examples/c3d_finetuning</span><br><span class="line"><span class="number">2</span>. <span class="keyword">sh</span> ucf101_finetuning.<span class="keyword">sh</span></span><br><span class="line"><span class="number">3</span>. <span class="keyword">sh</span> ucf101_testing.<span class="keyword">sh</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="4-Classify_C3D_feature_using_SVM">4.Classify C3D feature using SVM</h2><p>After extracting features for batchs in each video using C3D tools, in orde to use SVM to classify the videos, we must get a descriptor for each video. We average the c3d features for each video, i.e., sum up those 4096 dimension’s data and calculate the mean of them. I use matlab code below to do this job(using offered funtion <code>read_binary_blob</code>):</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[]</span>= <span class="title">read_ucf101_c3d_feat</span><span class="params">(output_list_relative)</span></span></span><br><span class="line"><span class="comment">% Read c3d features (fc6) for videos in ucf101 dataset.</span></span><br><span class="line"><span class="comment">% For each video, average all its features and get a video descriptor.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">% rather than fileread, importdata save each line separetely.</span></span><br><span class="line">    dir_list = importdata(output_list_relative);</span><br><span class="line"></span><br><span class="line">    dim_feat = <span class="number">4096</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">size</span>(dir_list, <span class="number">1</span>)</span><br><span class="line">        dir_str = char(dir_list(<span class="built_in">i</span>));</span><br><span class="line">        feat_files = dir(<span class="matrix">[dir_str, <span class="string">'/*.fc6-1'</span>]</span>);</span><br><span class="line">        num_feat = <span class="built_in">length</span>(feat_files);</span><br><span class="line">        feat = <span class="built_in">zeros</span>(num_feat, dim_feat);</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span> : num_feat</span><br><span class="line">            feat_path = strcat(dir_str, <span class="string">'/'</span>, feat_files(<span class="built_in">j</span>).name);</span><br><span class="line">            <span class="matrix">[~, feat(j,:)]</span> = read_binary_blob(feat_path);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        avg_feat = mean(feat, <span class="number">1</span>);</span><br><span class="line">        avg_feat_double = double(avg_feat);</span><br><span class="line">        fID = fopen(strcat(dir_str, <span class="string">'/c3d.fc6'</span>), <span class="string">'w'</span>);</span><br><span class="line">		<span class="comment">% libsvm requires that input data must be double</span></span><br><span class="line">        fwrite(fID, avg_feat_double, <span class="string">'double'</span>);</span><br><span class="line">        fclose(fID);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>The input parameter is the file each line is a relative path to each video frames from the location of script. for example:</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">..<span class="regexp">/output/</span>c3d<span class="regexp">/ApplyEyeMakeup/</span>v_ApplyEyeMakeup_g01_c01</span><br></pre></td></tr></table></figure>
<p>It takes about ten minutes to run this script.  </p>
<p>When use libsvm to classify video features, there are two phases: training and testing. The declaration of training and testing functions are: </p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = libsvmtrain(train_label_vector, train_data_matrix, options);</span><br><span class="line"><span class="matrix">[label, accuracy, prob]</span> = libsvmpredict(test_label_vector, test_data_matrix, model, options);</span><br></pre></td></tr></table></figure>
<p><code>train_label_vector</code> is a m by 1 vector, each element is a double value. <code>train_data_matrix</code> is a m by n matrix, each row is the data of one video. It is similar for predicting function.  </p>
<p>In order to construct input data in right way, I write several  wrapper functions for training and testing, which is more convenient to running:</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% create_svm_input_data.m</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[data_matrix]</span> = <span class="title">create_svm_input_data</span><span class="params">(output_list_train)</span></span></span><br><span class="line"><span class="comment">% read the c3d feature(fc6) for each video, construct libsvm format data.</span></span><br><span class="line"></span><br><span class="line">    dim_feat = <span class="number">4096</span>;</span><br><span class="line">    dir_list = importdata(output_list_train);</span><br><span class="line">    num_train_video = <span class="built_in">size</span>(dir_list, <span class="number">1</span>);</span><br><span class="line">    data_matrix = <span class="built_in">zeros</span>(num_train_video, dim_feat);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : num_train_video</span><br><span class="line">        feat_path = strcat(char(dir_list(<span class="built_in">i</span>)), <span class="string">'/c3d.fc6'</span>);</span><br><span class="line">        fid = fopen(feat_path, <span class="string">'r'</span>);</span><br><span class="line">        data = fread(fid, <span class="string">'double'</span>);</span><br><span class="line">        fclose(fid);</span><br><span class="line"></span><br><span class="line">        normed_data = data / norm(data);</span><br><span class="line">        data_matrix(<span class="built_in">i</span>, :) = normed_data;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>The <code>output_list_train</code> is the file contains relative path to each video directory. like:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">../output/c3d/YoYo/v_YoYo_g07_c02</span><br></pre></td></tr></table></figure></p>
<p>And then there is the file to train svm:<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% train_ucf101.m</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[model]</span> = <span class="title">train_ucf101</span><span class="params">(label_file_path, data_file_path, varargin)</span></span></span><br><span class="line">    label_int = load(label_file_path);</span><br><span class="line">    label_double = double(label_int);</span><br><span class="line">    data = create_svm_input_data(data_file_path);</span><br><span class="line">    model = libsvmtrain(label_double, data, varargin<span class="cell">&#123;:&#125;</span>);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>
<p>The <code>label_file_path</code> is the complete path to the file contains all training labels, including the file name, for example, <code>label_file_path</code> can be:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/data/foo/training_label.txt</span><br></pre></td></tr></table></figure></p>
<p>And each line in <code>training_label.txt</code> contains only one label, for example:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># training_label.txt</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>There is the matlab file to test svm:</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% test_ucf101.m</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[label, accuracy, predict_prob]</span> = <span class="title">test_ucf101</span><span class="params">(test_label_path, test_data_path, model, varargin)</span></span></span><br><span class="line">    label_int = load(test_label_path);</span><br><span class="line">    label_double = double(label_int);</span><br><span class="line">    label_size = <span class="built_in">size</span>(label_double)</span><br><span class="line">    data = create_svm_input_data(test_data_path);</span><br><span class="line">    data_size = <span class="built_in">size</span>(data)</span><br><span class="line">    <span class="matrix">[label, accuracy, predict_prob]</span> = libsvmpredict(label_double, data, model, varargin<span class="cell">&#123;:&#125;</span>);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>Note we can use <code>varagin</code> to pass parameters from a wrapper function to an internal function.</p>
<h2 id="5-Reference">5.Reference</h2><ol>
<li><a href="https://docs.google.com/document/d/1-QqZ3JHd76JfimY4QKqOojcEaf5g3JS0lNh-FHTxLag/edit" target="_blank" rel="external">C3D User Guide</a>.</li>
<li><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/" target="_blank" rel="external">LIBSVM</a>.</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p><a href="https://github.com/facebook/C3D">C3D</a> is a deep learning tool which is modified version of BVLC <a href="https://github.com/BVLC/caffe">caffe</a> to support 3D convolution and pooling. it was released by Facebook. In the field of human action recognition, C3D feature of video clip is the state-of-the-art feature. In this blog, I write some notes for using this tool in practice.<br>]]>
    
    </summary>
    
      <category term="Caffe" scheme="http://vra.github.io/tags/Caffe/"/>
    
      <category term="DeepLearning" scheme="http://vra.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[c++11新特性：default和delete]]></title>
    <link href="http://vra.github.io/2016/01/17/default-deleted/"/>
    <id>http://vra.github.io/2016/01/17/default-deleted/</id>
    <published>2016-01-17T02:30:39.000Z</published>
    <updated>2017-01-08T09:23:44.754Z</updated>
    <content type="html"><![CDATA[<h2 id="缘起">缘起</h2><p>今早在美国的本科室友问了我下面的C++代码是什么意思：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="preprocessor">#<span class="keyword">ifdef</span>  _CV_H</span></span><br><span class="line"><span class="preprocessor">#<span class="keyword">define</span> _CV_H</span></span><br><span class="line"><span class="keyword">class</span> cv&#123;</span><br><span class="line">	cv(<span class="keyword">const</span> cv&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">	cv&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> cv&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">	cv(cv&amp;&amp;);</span><br><span class="line">	cv&amp; <span class="keyword">operator</span>=(cv&amp;&amp;);</span><br><span class="line">&#125;;</span><br><span class="line"><span class="preprocessor">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure></p>
<p>什么，<code>delete</code>居然还有这种神奇的用法？我确实以前没看过。所以我跑到实验室，自己查了些资料，大概明白这些代码是个什么意思了，所以记录下来。<br><a id="more"></a></p>
<h2 id="default和delete">default和delete</h2><p>在C++03的标准里面，如果程序代码里面没有写默认构造函数(像<code>cv();</code>)，复制构造函数，复制赋值函数(像<code>cv cv2=cv1;</code>)和析构函数，则编译器会自动添加这些函数。当程序里面写了构造函数的时候，编译器就不会自动添加默认构造函数了。<br>那如果我想让一个类的实例不能通过复制构造函数来生成，该怎么办呢？一般的方法是将复制构造函数和复制赋值函数声明为<code>private</code>，而且不去具体实现它们，这样就达到了目的。<br>但这样做其实是很tricky的方式，相当于利用c++的一些特性碰巧来实现，总感觉不是正确的方法。<br>C++11里面可以用<code>default</code>来指定使用默认的构造函数，而且可以通过<code>delete</code>来显式地禁止一些方法，如复制构造函数和复制赋值操作，如下例：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> NonCopyable&#123;</span><br><span class="line">	NonCopyable() = <span class="keyword">default</span>;</span><br><span class="line">	NonCopyable(<span class="keyword">const</span> NonCopyable&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">	NonCopyable&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> NonCopyable&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>这个例子里面，第一条语句是强制编译器生成默认构造函数作为struct的构造函数；第2，3句就是显式地禁用复制构造函数和复制赋值操作。  </p>
<h2 id="move_constructor">move constructor</h2><p>既然禁止了复制构造函数，那么如果想通过已经生成的类的实例来初始化一个新的同类的实例，要怎么操作呢？显然，<code>cv cv2(cv1)</code>和<code>cv cv2=cv1;</code>是不可以用的了，因为复制构造函数已经被禁止了。<br>C++11新定义了一个叫做<code>move constructor</code>的构造函数，签名方法如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">class_name(class_name &amp;&amp;);</span><br><span class="line">class_name&amp; <span class="keyword">operator</span>=(class_name &amp;&amp;);</span><br></pre></td></tr></table></figure></p>
<p>调用时这样用：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">class_name c1;</span><br><span class="line">class_name c2=std::move(c1);</span><br><span class="line">class_name c3(std:move(c1));</span><br></pre></td></tr></table></figure></p>
<p>所谓<code>move</code>，我的理解就是类似于指针一样的概念，move生成的新的实例和原先的实例是由同一个指针指向的，即实际上是同一个实例。而且<code>&amp;&amp;</code>这个符号让人联想到了<code>**</code>，可能也是这个意思吧。<br>这就是这个新特性的简单介绍，感觉应用场合不是很多，可能是我还没搞懂的原因吧。<br>看了<a href="http://blog.csdn.net/luotuo44/article/details/46779063" target="_blank" rel="external">这篇博客</a>,发现这个新特性还是很强大的啊～还是too young.<br>从<a href="https://msdn.microsoft.com/en-us/library/hh567368.aspx#defaultedanddeleted" target="_blank" rel="external">这里</a>看到，vs2012里面还不支持这个特性，vs2013才开始支持。在g++中，可以通过使用<code>-std=c++11</code>来启用这个特性(我用的是g++4.9.2,默认是开启的)。  </p>
<p>参考链接:<br><a href="http://blog.csdn.net/pongba/article/details/1684519" target="_blank" rel="external">http://blog.csdn.net/pongba/article/details/1684519</a><br><a href="https://en.wikipedia.org/wiki/C%2B%2B11#Explicitly_defaulted_and_deleted_special_member_functions" target="_blank" rel="external">https://en.wikipedia.org/wiki/C%2B%2B11#Explicitly_defaulted_and_deleted_special_member_functions</a><br><a href="http://en.cppreference.com/w/cpp/language/move_constructor" target="_blank" rel="external">http://en.cppreference.com/w/cpp/language/move_constructor</a><br><a href="http://stackoverflow.com/questions/7421825/c11-features-in-visual-studio-2012" target="_blank" rel="external">http://stackoverflow.com/questions/7421825/c11-features-in-visual-studio-2012</a><br><a href="http://stackoverflow.com/questions/6077143/disable-copy-constructor" target="_blank" rel="external">http://stackoverflow.com/questions/6077143/disable-copy-constructor</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="缘起">缘起</h2><p>今早在美国的本科室友问了我下面的C++代码是什么意思：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="preprocessor">#<span class="keyword">ifdef</span>  _CV_H</span></span><br><span class="line"><span class="preprocessor">#<span class="keyword">define</span> _CV_H</span></span><br><span class="line"><span class="keyword">class</span> cv&#123;</span><br><span class="line">	cv(<span class="keyword">const</span> cv&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">	cv&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> cv&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">	cv(cv&amp;&amp;);</span><br><span class="line">	cv&amp; <span class="keyword">operator</span>=(cv&amp;&amp;);</span><br><span class="line">&#125;;</span><br><span class="line"><span class="preprocessor">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure></p>
<p>什么，<code>delete</code>居然还有这种神奇的用法？我确实以前没看过。所以我跑到实验室，自己查了些资料，大概明白这些代码是个什么意思了，所以记录下来。<br>]]>
    
    </summary>
    
      <category term="C++" scheme="http://vra.github.io/tags/C/"/>
    
      <category term="学习总结" scheme="http://vra.github.io/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[机器学习笔记-总结]]></title>
    <link href="http://vra.github.io/2015/12/12/machine-learning-summary/"/>
    <id>http://vra.github.io/2015/12/12/machine-learning-summary/</id>
    <published>2015-12-12T05:43:42.000Z</published>
    <updated>2017-01-08T09:23:44.790Z</updated>
    <content type="html"><![CDATA[<p>机器学习笔记是我这学期在上”统计学习”这门课时学习到的内容的一个总结.因为过往很多学过的知识,现在大多都已经忘掉了,而统计机器学习的内容则很重要,我可不能再上过就忘掉,所以在复习的时候把这些内容都记录下来,以便以后查阅.<br><a id="more"></a></p>
<h2 id="基本概念">基本概念</h2><ol>
<li>学习：一个系统在完成一项任务T的时候,使用了数据E,使得在评判标准P下,性能获得了提升,这就是学习  </li>
<li>统计学习的对象是数据,关于统计学习的基本假设是：同类数据服从一定的统计规律性,即数据都是独立同分布的  </li>
<li>统计学习中的问题可以分为4大类,分别是 <ul>
<li>监督学习：解决<strong>预测</strong>问题, 根据预测变量是否连续,分为回归问题和分类问题</li>
<li>非监督学习：解决<strong>分析</strong>型问题, 分为聚类(.如图像分割).,密度估计和关联分析三类</li>
<li>半监督学习：问题中既有分析的部分,又有预测的部分,主要有主动学习(.先分析,出现问题时向人要数据(.如分类label).).</li>
<li>增强学习：在合适过程中,根据反馈做新的判断,主动增强自身的学习,典型应用：机器人足球</li>
</ul>
</li>
<li>统计学习的基本步骤<ol>
<li>获取数据(.即E).</li>
<li>确定用什么样的数学模型,所有模型构成假设空间</li>
<li>有了一组模型后,确定策略,即如何来找到最优的模型</li>
<li>写出模型选择策略的算法</li>
<li>通过学习得到最优模型</li>
<li>用学习到的模型来在新的数据上进行分析和预测</li>
</ol>
</li>
<li>学习的三大要素：模型,策略,算法.模型是知识的集合,策略是模型选择的准则,算法就是学习的具体方法</li>
</ol>
<h2 id="模型的种类">模型的种类</h2><ol>
<li>线性模型(Linear model)：y=ax+b,算法实例：线性回归(Linear regression)</li>
<li>对数线性(Log-linear model)：算法实例：逻辑斯蒂回归(Logistic regression)</li>
<li>稀疏模型(Sparse model)：形式也是y=ax+b,但a很稀疏,算法实例：稀疏分解(Sparese decomposition)</li>
<li>非线性核方法(Non-linear by kernel),利用核技巧将非线性问题转化为线性问题,实例：支持向量机(SVM, support vector machine)</li>
<li>层级非线性(Layered nonlinear)：实例：神经网络(Neural Network)</li>
<li>图模型(Graphic model)：将数据看作随机变量的话,它们之间的依赖关系可用图来表示,实例：贝叶斯网络(Bayes network)</li>
<li>树模型(Tree model)：对输入变量进行分块处理,每个子块有可以使用别的机器学习算法,实例：决策树(Decision tree),提升数(Boosting tree)</li>
<li>混合模型(Mixture model)：实例：聚类(Clustering)<br>上述模型中,1-5为非概率模型,6,8为概率模型,7为混合类型,概率模型和非概率模型可能都有.</li>
</ol>
<h2 id="学习的策略">学习的策略</h2><p>策略是模型选择的准则,为了量化模型的好坏,我们定义了损失函数和风险函数<br>损失函数(Loss function)：也叫代价函数(Cost function),用来度量模型对于<strong>一个</strong>输入<code>X</code>产生的预测值<code>f(x)</code>与真实值<code>Y</code>之间的差异的大小.常见的损失函数有:</p>
<ol>
<li>0-1 损失函数(0-1 loss function)<br><img src="http://7xlt5t.com1.z0.glb.clouddn.com/01loss.png" alt=""></li>
<li>平方损失函数(Square loss function)<br><img src="http://7xlt5t.com1.z0.glb.clouddn.com/pingfang.png" alt=""></li>
<li>绝对值损失函数(Absolute loss function)<br><img src="http://7xlt5t.com1.z0.glb.clouddn.com/jueduizhi.png" alt=""></li>
<li>对数损失函数(Log loss function)<br><img src="http://7xlt5t.com1.z0.glb.clouddn.com/duishu.png" alt=""><br>风险函数是损失函数的期望,即将模型的输入输出<code>XY</code>作为随机变量,风险函数就是模型<code>f(X)</code>关于联合分布<code>P(X,Y)</code>的平均意义下的损失.风险函数的值越小,表示模型预测结果越准确,这种模型就越好,所以机器学习的目的就是最小化风险函数(Rish miniization).需要注意的是：<code>P(X,Y)</code>是未知的<br>如果给定数据集,我们可以计算在该数据集上的平均损失,这个损失定义为经验风险.经验风险在数据量足够大的时候,能很好的近似期望风险,但在数据量较少的时候误差会比较大.<br>在经验风险的基础上,加上表示模型复杂度的正则化项,则构成结构风险.结构风险能有效的防止过拟合,因为结构风险要求经验风险和模型复杂度同时都小.  </li>
</ol>
<h2 id="经典机器学习算法">经典机器学习算法</h2><p>分类算法：</p>
<ol>
<li>K近邻(KNN, K Nearest Neighbor)</li>
<li>朴素贝叶斯(Naive Bayes)</li>
<li>支持向量机(SVM, Support Vector Machine)</li>
<li>AdaBoost </li>
</ol>
<p>聚类算法：</p>
<ol>
<li>K-Means </li>
<li>期望最大化(EM, Expectation Maximization)</li>
</ol>
<p>回归算法：</p>
<ol>
<li>脊回归(Ridge regression)</li>
<li>Lasso回归(The Least Absolute Shrinkage and Selectionator Operator)</li>
</ol>
<p>关联分析算法：</p>
<ol>
<li>先验算法(Aprior)</li>
</ol>
<p>降维算法：</p>
<ol>
<li>主成份分析法(PCA, Principal Component Analysis)</li>
<li>局部线性嵌入(Locally linear embedding)</li>
</ol>
<h2 id="欠拟合(under-fitting)和过拟合(over-ftting)">欠拟合(under-fitting)和过拟合(over-ftting)</h2><p>在训练模型的时候,有的时候需要选择不同的复杂度(.如不同参数的个数).来训练,不同的复杂度体现了模型对训练数据的拟合程度.<br>如果参数过少,模型过于简单,则模型不能很好的拟合训练数据,这种情况称为欠拟合,很显然,欠拟合因为连训练数据的规律都没有学习到,所以对于预测,性能肯定不会太好.<br>另一方面,如果参数太多,模型过于复杂,则对训练数据可以做到特别好的拟合,但由于训练数据是有噪声和误差的,这种情况会将训练数据的噪声和误差都考虑进来,在测试集上性能反而会下降.下面是训练误差和测试误差与模型复杂度的关系<br><img src="http://7xlt5t.com1.z0.glb.clouddn.com/overfitting.gif" alt=""></p>
<h2 id="交叉验证(Cross_Validation)">交叉验证(Cross Validation)</h2><p>学习的最终目的是预测,即学习一个模型,使得对未知数据能很好地预测.在实际操作中,一般将数据集分为3部分：训练集,验证集和测试集.为了验证在训练集上学习到的模型好坏,需要现在验证集上进行验证.实际中数据总是不充足的,所以需要重复使用数据,采用交叉验证的方法.最常用的交叉验证方法是S折交叉验证方法.<br>S折交叉验证方法(S-fold cross validation)：随机地将数据切分为S个互不相交的子集,然后利用S-1个子集的数据训练模型,利用余下的1个子集作为测试集.测试集的选择有S中情况,所以这种验证可以进行S次.对每个模型,都进行S次训练和验证,然后求出平均测试误差,将平均测试误差最小的模型作为最优模型.<br>当数据量特别少的时候,我们将每个数据分为一个子集,即如果有N个数据,则S=N,这种方法称为留一交叉验证(Leave-one-out cross validation).</p>
<h2 id="判别模型(Discriminative_model)和生成模型(generative_model)">判别模型(Discriminative model)和生成模型(generative model)</h2><p>生成式方法：对于某个给定的输入<code>X</code>,先学习得到联合分布<code>P(X,Y)</code>,再计算<code>P(Y|X)</code>,也即该方法考虑给定输入<code>X</code>,输出<code>Y</code>是怎么生成的,要求得到一个关于整体的信息,即对<code>P(X,Y)</code>进行建模.<br>生成式方法应用更广,适用于各种机器学习问题,而且收敛速度快,而且对于有隐变量的情况,也适用.但由于需要建模<code>XY</code>的联合分布,所以不能进行降维处理.<br>常见的生成式模型有朴素贝叶斯法和隐马尔科夫模型.<br>判别式方法：对于某个给定的输入<code>X</code>,直接给出预测值<code>f(X)</code>或<code>P(Y|X)</code>.该方法关注的是对于给定的输入<code>X</code>,应该预测什么样的输出<code>Y</code>,而不用去考虑数据整体的分布这些信息,即对<code>P(Y|X)</code>建模.<br>常见的判别模型有KNN,感知机,决策树,逻辑斯蒂回归,最大熵模型,SVM,AdaBoost,条件随机场等.<br>判别式方法只能用于分类和回归问题,可以对<code>X</code>进行降维处理.  </p>
]]></content>
    <summary type="html">
    <![CDATA[<p>机器学习笔记是我这学期在上”统计学习”这门课时学习到的内容的一个总结.因为过往很多学过的知识,现在大多都已经忘掉了,而统计机器学习的内容则很重要,我可不能再上过就忘掉,所以在复习的时候把这些内容都记录下来,以便以后查阅.<br>]]>
    
    </summary>
    
      <category term="机器学习 总结" scheme="http://vra.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[GPU并行计算和CUDA编程(2)-GPU体系架构概述]]></title>
    <link href="http://vra.github.io/2015/09/12/gpu-programming-2/"/>
    <id>http://vra.github.io/2015/09/12/gpu-programming-2/</id>
    <published>2015-09-12T15:14:18.000Z</published>
    <updated>2017-01-08T09:23:44.778Z</updated>
    <content type="html"><![CDATA[<h2 id="并行计算">并行计算</h2><p>并行计算的定义： 应用多个计算资源来解决<strong>同一个计算问题</strong></p>
<h3 id="一些名词">一些名词</h3><ol>
<li>Flynn矩阵：<br>SISD(Single Instruction Single Data),<br>SIMD(Single Instruction Multiple Data),<br>MISD(Multiple Instruction Single Data),<br>MIMD(Multiple Instruction Multiple Data),<br>由 SISD,SIMD，MISD，MIMD组成的矩阵就是Flynn矩阵。从前往后，4种结构越来越复杂。 </li>
<li>共享存储和分布式存储   </li>
<li>通信和同步  </li>
<li>加速比，并行开销，拓展性</li>
</ol>
<a id="more"></a>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script> 
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<h3 id="Amdahl定律">Amdahl定律</h3><p>  $$1. speed rate = \frac{1}{1-P} $$<br>其中P是可以并行的部分，即加速比与任务中不可并行部分的大小成正比，如果完全不可并行，即P = 0，则speed rate = 1，即不加速；如果完全可以并行，即P = 1, 则$speed rate = \infty$, 即加速无穷大倍。<br>  $$2. speed rate = \frac{1}{\frac{P}{N} + S} $$<br> 其中N是处理器个数，P是可以并行的部分，S是不可以并行，只能串行的部分。可以看到，当N趋近无穷时，speed rate 只取决于S，即不可并行部分是系统的瓶颈所在。 </p>
<h2 id="GPU结构">GPU结构</h2><p>CPU和GPU的内部结构的对比图如下：<br><img src="http://7xlt5t.com1.z0.glb.clouddn.com/cpu_gpu_schema.gif" alt=""><br>图中绿色的为ALU（运算逻辑单元，Arithmetic Logic Unit）, 可以看出GPU相比CPU，多了很多ALU，而且ALU占据了内部空间的绝大部分，所以可以看出GPU是对运算很强调的芯片。</p>
<p>下图是一个GPU核的结构，图中所有8个ALU共用一个指令单元Fetch/Decode, 而Ctx则是每个ALU独有的存储上下文，所以，只是一种SIMD结构。<br><img src="http://7xlt5t.com1.z0.glb.clouddn.com/gpu-core.png" alt=""></p>
<h3 id="分支问题">分支问题</h3><p>由于每个ALU的Ctx不同，所以有可能会出现分支，这时候8个ALU的指令可能会出现分叉，即各自走了不同的路，没法共享同一个指令了，这种结构就会失效。为了解决这个问题，将所有可能出现的分支用<code>if/else</code>来表示，让每个ALU都进行判断，如下图所示：<br><img src="http://7xlt5t.com1.z0.glb.clouddn.com/gpu-branch.jpg" alt=""></p>
<p>从图中我们可以看到，每个ALU都进行了<code>if/else</code>的判断，有的ALU走了<code>if</code>部分，有的ALU走了<code>else</code>部分，这样8个ALU就可以共用一个Fetch/Decode单元了。但因为每个ALU都要进行判断，所以做了一部分无用功，牺牲了部分性能，性能最差的时候只有1/8的有用功，即只有1个ALU选择<code>if</code>或选择<code>else</code>，其他7个ALU都做了无用功，性能只有1/8。  </p>
<!--
###停滞问题（Stall）
在GPU处理问题的过程中，可能有的指令需要从别的地方读取数据，比较好似
-->
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="并行计算">并行计算</h2><p>并行计算的定义： 应用多个计算资源来解决<strong>同一个计算问题</strong></p>
<h3 id="一些名词">一些名词</h3><ol>
<li>Flynn矩阵：<br>SISD(Single Instruction Single Data),<br>SIMD(Single Instruction Multiple Data),<br>MISD(Multiple Instruction Single Data),<br>MIMD(Multiple Instruction Multiple Data),<br>由 SISD,SIMD，MISD，MIMD组成的矩阵就是Flynn矩阵。从前往后，4种结构越来越复杂。 </li>
<li>共享存储和分布式存储   </li>
<li>通信和同步  </li>
<li>加速比，并行开销，拓展性</li>
</ol>]]>
    
    </summary>
    
      <category term="C++" scheme="http://vra.github.io/tags/C/"/>
    
      <category term="CUDA" scheme="http://vra.github.io/tags/CUDA/"/>
    
      <category term="GPU" scheme="http://vra.github.io/tags/GPU/"/>
    
      <category term="并行计算" scheme="http://vra.github.io/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"/>
    
      <category term="计算机视觉" scheme="http://vra.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[GPU并行计算和CUDA编程(1)-CPU体系架构概述]]></title>
    <link href="http://vra.github.io/2015/09/12/gpu-programming-1/"/>
    <id>http://vra.github.io/2015/09/12/gpu-programming-1/</id>
    <published>2015-09-12T13:09:10.000Z</published>
    <updated>2017-01-08T09:23:44.754Z</updated>
    <content type="html"><![CDATA[<p>今天和实验室同学去听了周斌老师讲的《GPU并行计算和CUDA程序开发及优化》（课程主页：<a href="http://acsa.ustc.edu.cn/HPC2015/nvidia/" target="_blank" rel="external">http://acsa.ustc.edu.cn/HPC2015/nvidia/</a>），觉得老师讲得非常清晰，举了很多恰当的例子，将复杂的计算机中的情景和术语准确地描述成了简单的生活中的场景，使学生很容易就理解了。而我在今天的课程中也学到了很多东西，我想趁热打铁记下来，以后看起来更方便点。 </p>
<p>CPU是串行处理器，而GPU是并行处理器。CPU适合处理通用型的问题，如指令执行和数值计算并重，相当于是一个”通才”；而GPU适合运算密集和高度并行的任务，相当于是一个”专才”，将数值并行运算速度发挥到极致。在讨论GPU之前，先来看看CPU的体系架构的一些内容。 </p>
<a id="more"></a>
<h2 id="一些概念">一些概念</h2><p>CPU的指令分3类，分别是算术、访存和控制。算术包括加减乘除等操作（在计算机中转化为加或乘来做），访存表示对数据寄存器进行读写，控制表示跳转，分支等操作。  </p>
<p>CPU程序的最优化目标是：</p>
<p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>$$\frac{cycle}{instruction}\times\frac{seconds}{cycle}$$<br>其中前一项是每条指令执行的时钟周期数，简称为CPI（Cycle Per Instruction)，后一项即时钟周期。 </p>
<p>CPU的指令顺序是取指-&gt;译码-&gt;执行-&gt;访存-&gt;写回。  </p>
<p>为了提高程序执行的效率，CPU里面采用了流水线的设计，将一个任务分割成多个任务片段，在同一时刻，每个任务片段可能处理不同的指令。注意：我们说CPU是串行处理器，是从宏观的角度来说的，底层的流水线实现实际是并行的。此外，流水线使得单个指令的执行周期变长了，因为增加了任务时间段的切割，可能会增加额外的时间开销，但从整体上来讲，效率显然是提高了。 </p>
<h2 id="流水线存在的一些问题">流水线存在的一些问题</h2><p>流水线中，可能会出现停滞（stall）的问题，就是对某个任务片段，前面的指令已经执行完了，而后面的指令还没有传过来，出现了停滞。 </p>
<p>另外一个问题是可能存在分支，使得流水线不能正常地高速执行了。为了解决分支的问题，提出了两种方法，一种是分支预测（branch prediction），另一种是分支断定（branch predication）。 </p>
<p>分支预测就是根据历史记录或基于全局记录来进行预测下一步需要执行哪条命令，然后减少分支的开销。分支预测能达到90%的准确率，但是增加了额外的硬件电路设计上的面积（因为需要记录历史分支数据，需要增加额外的存储器件），也可能会增加延迟。 </p>
<p>分支断定就是类似与每次都将所有可能的下一条执行尝试一遍，避免了分支预测。可以这样认为：分支断定就像switch语句，每个选项都进行比较，而分支预测就相当于if/else语句，需要使用分支预测器。 </p>
<p>为了提升IPC（CPI的倒数），CPU又使用了超标量的方法，即增加流水线的宽度，相当于同时执行好几条流水线，这样效率又提高了，当然也是以增加芯片面积为代价的。 </p>
<h2 id="指令调度">指令调度</h2><p>因为有些指令之间是有依赖关系的，比如A指令是把加的结果写入到R1,B指令是读取R1中的数，所以B指令必须等A指令完成之后才能来执行。一般来讲，Read—After-Write（RAW）模式的语句之间有依赖关系，而别的，像WAW,WAR都是没依赖关系的。<br>为了解决指令依赖的问题，提出了2种方案：1是寄存器重命名，即将涉及冲突的寄存器重命名为不同的寄存器，就解决了依赖问题；2是乱序执行，即将所有指令放到一个重拍缓冲区（ROB，Recorder Buffer）中，根据一定的算法，重新执行各语句，使得各语句之间无依赖关系。 </p>
<h2 id="缓存机制">缓存机制</h2><p>CPU的缓存机制利用了1.时间临近性和空间临近性。</p>
<h2 id="CPU内部的并行性">CPU内部的并行性</h2><p>CPU内部也有并行计算，体现在下面3个层次：</p>
<ol>
<li>指令级，如超标量就是通过增加流水线达到并行效果。</li>
<li>数据级，如矢量运算。如下面代码：</li>
</ol>
<pre><code class="cpp"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++)
{
    C[i] = A[i] + B[i];
}
</code></pre>
<p> 执行的时候可以通过矢量运算，将循环运算并行地计算，如下：</p>
<pre><code class="cpp">C[<span class="number">0</span>] = A[<span class="number">0</span>] + B[<span class="number">0</span>];
C[<span class="number">1</span>] = A[<span class="number">1</span>] + B[<span class="number">1</span>];
C[<span class="number">2</span>] = A[<span class="number">2</span>] + B[<span class="number">2</span>];
C[<span class="number">3</span>] = A[<span class="number">3</span>] + B[<span class="number">3</span>];
C[<span class="number">4</span>] = A[<span class="number">4</span>] + B[<span class="number">4</span>];
</code></pre>
<ol>
<li>线程级别的并行。每个CPU有1-2个活动线程。</li>
</ol>
<h2 id="多核相关">多核相关</h2><p>CPU多核之间，只共享最后一级缓存。<br>多核之间数据的访问安全等问题，需要有：</p>
<ol>
<li>锁</li>
<li>一致性： 谁的数据是正确的</li>
<li>同一性： 哪个数据是正确的</li>
</ol>
<h2 id="其他">其他</h2><p>尽管在IEEE的规范中，浮点数使用64bit空间来存储，但在CPU中，浮点数的精度是拓展到80bit来计算的，所以CPU中浮点数精度比GPU（64bit）中要高。 </p>
]]></content>
    <summary type="html">
    <![CDATA[<p>今天和实验室同学去听了周斌老师讲的《GPU并行计算和CUDA程序开发及优化》（课程主页：<a href="http://acsa.ustc.edu.cn/HPC2015/nvidia/">http://acsa.ustc.edu.cn/HPC2015/nvidia/</a>），觉得老师讲得非常清晰，举了很多恰当的例子，将复杂的计算机中的情景和术语准确地描述成了简单的生活中的场景，使学生很容易就理解了。而我在今天的课程中也学到了很多东西，我想趁热打铁记下来，以后看起来更方便点。 </p>
<p>CPU是串行处理器，而GPU是并行处理器。CPU适合处理通用型的问题，如指令执行和数值计算并重，相当于是一个”通才”；而GPU适合运算密集和高度并行的任务，相当于是一个”专才”，将数值并行运算速度发挥到极致。在讨论GPU之前，先来看看CPU的体系架构的一些内容。 </p>]]>
    
    </summary>
    
      <category term="C++" scheme="http://vra.github.io/tags/C/"/>
    
      <category term="CUDA" scheme="http://vra.github.io/tags/CUDA/"/>
    
      <category term="GPU" scheme="http://vra.github.io/tags/GPU/"/>
    
      <category term="并行计算" scheme="http://vra.github.io/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"/>
    
      <category term="计算机视觉" scheme="http://vra.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[初探Grunt]]></title>
    <link href="http://vra.github.io/2015/07/04/grunt-configure/"/>
    <id>http://vra.github.io/2015/07/04/grunt-configure/</id>
    <published>2015-07-04T12:17:57.000Z</published>
    <updated>2017-01-08T09:23:44.734Z</updated>
    <content type="html"><![CDATA[<p>最近打算学习一些web编程的知识，今天学习了Grunt这个工具的用法，这里简要地对学习的知识点进行个总结。</p>
<h2 id="1-_Grunt是什么">1. Grunt是什么</h2><p>Grunt网站上的副标题是”The Javascript Task Runner”，是用来实现Javascript编程自动化的一个工具，类似<code>make</code>工具体系。只要设置好<code>Gruntfile</code>（类比<code>Makefile</code>），就可以使用<code>grunt</code>命令来自动执行javascript代码的清理、重新生成等任务。Grunt生态圈里面有大量的插件，Grunt工具就是使用这些插件来实现自动化。</p>
<a id="more"></a>
<h2 id="2-_如何安装Grunt">2. 如何安装Grunt</h2><p>Grunt通过<code>npm</code>命令来安装，所以需要首先安装npm。npm是nodejs package manager的缩写，是nodejs的包管理工具。在新版的nodejs里面默认包含了npm，所以只需要安装最新班的nodejs即可，访问nodejs官方网站下载最新版的nodejs。<br>之后通过npm安装<code>grunt-cli</code>，即Grunt command line interface。为了在所有目录下都可以使用grunt命令，需要加-g参数，指令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g grunt-cli</span><br></pre></td></tr></table></figure>
<p>注意：有的发行版在使用<code>npm</code>命令时需要root权限，前面要加<code>sudo</code>命令。<br>其实安装完grunt-cli后，并没有安装grunt。这里面的原理大概是这样的：grunt-cli只用来寻找通过nodejs的<code>require</code>工具(或在package.json的dependencies)已经安装好的本地的grunt,然后执行之。可以看源代码查看工作原理。</p>
<h2 id="3-_使用Grunt工具前需要准备哪些东西">3. 使用Grunt工具前需要准备哪些东西</h2><p>按理来说，使用<code>grunt</code>命令，只需要有个<code>Gruntfile</code>就可以了，但是上文提到，grunt task runner需要在每个项目中单独安装，所以还得有个保存项目元数据的<code>package.json</code>文件。</p>
<p>在每个nodejs项目中，都有个<code>package.json</code>文件来保存这个项目的名称、版本、依赖库等元数据。</p>
<p><code>package.json</code>可以使用命令<code>npm init</code>交互式地生成。在生成该文件后，可以使用<code>npm install</code>在当前项目目录下安装依赖库。</p>
<p>此外，在项目目录下安装工具库并使用<code>--save-dev</code>或<code>--save</code>参数，可以将安装的工具自动加入到该项目的依赖库中。其中<code>--save</code>命令将安装的工具名称和版本号加入到<code>dependencie</code>部分，<code>--save-dev</code>则加到<code>devDependencies</code>部分。如下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install grunt --save-dev</span><br></pre></td></tr></table></figure>
<p>将安装grunt task runner 并将其名称和版本号自动加入到<code>devDependencies</code>部分。</p>
<p><code>Gruntfile</code>是<code>Gruntfile.js</code>(Javascript语言格式)和<code>Gruntfile.coffee</code>(CoffeeScript格式)之一,类似Make工具体系中的<code>Makefile</code>，用来保存配置信息，是Grunt工具的最主要文件。<br>下面是一个Gruntfile的示例格式，详细格式和说明请参阅官方文档。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">module</span>.exports = <span class="function"><span class="keyword">function</span>(<span class="params">grunt</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  grunt.initConfig(&#123;</span><br><span class="line">    jshint: &#123;</span><br><span class="line">      files: [<span class="string">'Gruntfile.js'</span>, <span class="string">'src/**/*.js'</span>, <span class="string">'test/**/*.js'</span>],</span><br><span class="line">      options: &#123;</span><br><span class="line">        globals: &#123;</span><br><span class="line">          jQuery: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    watch: &#123;</span><br><span class="line">      files: [<span class="string">'&lt;%= jshint.files %&gt;'</span>],</span><br><span class="line">      tasks: [<span class="string">'jshint'</span>]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  grunt.loadNpmTasks(<span class="string">'grunt-contrib-jshint'</span>);</span><br><span class="line">  grunt.loadNpmTasks(<span class="string">'grunt-contrib-watch'</span>);</span><br><span class="line"></span><br><span class="line">  grunt.registerTask(<span class="string">'default'</span>, [<span class="string">'jshint'</span>]);</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="4-_如何运行Grunt">4. 如何运行Grunt</h2><p>在<code>Gruntfile</code>写好之后，运行<code>grunt</code>命令，就会自动执行<code>Gruntfile</code>里面的语句了。so easy 是不是～</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>最近打算学习一些web编程的知识，今天学习了Grunt这个工具的用法，这里简要地对学习的知识点进行个总结。</p>
<h2 id="1-_Grunt是什么">1. Grunt是什么</h2><p>Grunt网站上的副标题是”The Javascript Task Runner”，是用来实现Javascript编程自动化的一个工具，类似<code>make</code>工具体系。只要设置好<code>Gruntfile</code>（类比<code>Makefile</code>），就可以使用<code>grunt</code>命令来自动执行javascript代码的清理、重新生成等任务。Grunt生态圈里面有大量的插件，Grunt工具就是使用这些插件来实现自动化。</p>]]>
    
    </summary>
    
      <category term="Web编程" scheme="http://vra.github.io/tags/Web%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Linux 下的source命令学习]]></title>
    <link href="http://vra.github.io/2015/07/03/source-command/"/>
    <id>http://vra.github.io/2015/07/03/source-command/</id>
    <published>2015-07-03T11:43:56.000Z</published>
    <updated>2017-01-08T09:23:44.734Z</updated>
    <content type="html"><![CDATA[<p>前些天在装opencl的<a href="http://www.freedesktop.org/wiki/Software/Beignet/" target="_blank" rel="external">beignet</a>实现版本时，发现wiki中里面有个点命令.，不知道具体含义就百度了下，结果学了一些相关的知识，记录如下。</p>
<a id="more"></a>
<h2 id="1-概述">1.概述</h2><p><code>source</code>命令是bash的内置命令，与点命令.等效，唯一不同的是点命令是<a href="http://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html#dot" target="_blank" rel="external">在POXIS下定义的]</a>。<code>source</code>命令的执行格式是<code>source script</code>，是在当前shell进程中依次执行script文件中的语句。那么与普通的 <code>sh script</code>和<code>./script</code>有什么不同呢？主要有两个不同点：</p>
<ol>
<li><code>source</code> 的执行是在当前进程中执行，而<code>sh script</code>和<code>./script</code>在执行的时候，当前进程会开辟一个新的子进程，然后在子进程中执行script中的语句。</li>
<li>使用<code>source</code>命令的文件不需要有执行权限，而./script方式执行的方式需要script文件有可执行权限（注意：<code>sh script</code> 不需要script文件有可执行权限）。</li>
</ol>
<h2 id="2-_测试实例">2. 测试实例</h2><p>我们可以举几个例子来展示上面提到的不同点(例子都摘自参考内容中的第1个链接)。</p>
<h3 id="实例1">实例1</h3><p>编写脚本test.sh如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> $$</span><br></pre></td></tr></table></figure>
<p>需要说明一下，在Linux中，每个进程都有一个独一无二的进程号，简称为<code>PID</code>。而<code>$$</code>就表示当前进程的<code>PID</code>。所以上述脚本的作用就是输出当前进程的<code>PID</code>。<br>我们可以用两种方式来执行这个脚本，先使用<code>source</code>命令来执行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="built_in">source</span> test.sh</span><br><span class="line"><span class="number">3824</span></span><br><span class="line">&gt; <span class="built_in">source</span> test.sh</span><br><span class="line"><span class="number">3824</span></span><br><span class="line">&gt; <span class="built_in">source</span> test.sh</span><br><span class="line"><span class="number">3824</span></span><br></pre></td></tr></table></figure>
<p>可以看到每次输出的结果都是3824。然后使用<code>sh script</code>方式来执行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; sh test.sh</span><br><span class="line"><span class="number">3884</span></span><br><span class="line">&gt; sh test.sh</span><br><span class="line"><span class="number">3889</span></span><br><span class="line">&gt; sh test.sh</span><br><span class="line"><span class="number">3894</span></span><br></pre></td></tr></table></figure>
<p>可以看到每次输出的结果都在改变。<br>这个测试说明：使用<code>source</code>命令在当前进程执行，而使用<code>sh script</code>命令则每次执行时都生成不同的子进程，在子进程中执行，执行完后面文件中的指令后再返回主进程。</p>
<h3 id="实例2">实例2</h3><p>编写测试脚本<code>test.sh</code>:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"FOO:"</span>$(env | grep FOO)</span><br><span class="line"><span class="built_in">export</span> FOO=foo</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"FOO:"</span>$(env | grep FOO)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"PWD:"</span><span class="variable">$PWD</span></span><br><span class="line"><span class="built_in">cd</span> mydir</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"PWD:"</span><span class="variable">$PWD</span></span><br></pre></td></tr></table></figure>
<p>这个脚本先是测试环境变量中是否包含名为<code>FOO</code>的环境变量，然后新建的环境变量<code>Foo=foo</code>。然后是输出当前所在目录，接着切换到当前目录的<code>mydir</code>子目录，然后再输出当前所在目录。<br>在执行这个脚本前，我们先检查下当前环境:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; env | grep FOO</span><br><span class="line">&gt; <span class="built_in">echo</span> <span class="variable">$PWD</span></span><br><span class="line">/home/yunfeng</span><br></pre></td></tr></table></figure>
<p>这说明当前环境中没有名为<code>FOO</code>的变量，当前所在路径为<code>/home/yunfeng</code>。<br>然后我们执行<code>sh test.sh</code>，输出为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FOO:</span><br><span class="line">FOO:FOO=foo</span><br><span class="line">PWD:/home/yunfeng</span><br><span class="line">PWD:/home/yunfeng/mydir</span><br></pre></td></tr></table></figure>
<p>然后我们再检查下当前环境：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; env | grep FOO</span><br><span class="line">&gt; <span class="built_in">echo</span> <span class="variable">$PWD</span></span><br><span class="line">/home/yunfeng</span><br></pre></td></tr></table></figure>
<p>这说明使用<code>sh test.sh</code>执行的时候，并没有改变当前进程的环境变量和所在路径，而只是改变了新建的子进程的环境变量和所在路径。此外我们还可以得出结论：当前进程新建shell子进程的时候为子进程复制了当前进程的环境变量（包括路径）。<br>然后使用<code>source</code>命令执行<code>test.sh</code>:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> test.sh</span><br><span class="line">FOO:</span><br><span class="line">FOO:FOO=foo</span><br><span class="line">PWD:/home/yunfeng</span><br><span class="line">PWD:/home/yunfeng/mydir</span><br></pre></td></tr></table></figure>
<p>然后检查当前环境：(其实可以发现，当前目录已经切换到<code>mydir</code>了)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; env | grep FOO</span><br><span class="line">FOO=foo</span><br><span class="line">&gt; <span class="built_in">echo</span> <span class="variable">$PWD</span></span><br><span class="line">/home/yunfeng/mydir</span><br></pre></td></tr></table></figure>
<p>可以看出使用<code>source</code>命令时，会改变当前进程的环境变量。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>前些天在装opencl的<a href="http://www.freedesktop.org/wiki/Software/Beignet/">beignet</a>实现版本时，发现wiki中里面有个点命令.，不知道具体含义就百度了下，结果学了一些相关的知识，记录如下。</p>]]>
    
    </summary>
    
      <category term="Linux" scheme="http://vra.github.io/tags/Linux/"/>
    
      <category term="Shell" scheme="http://vra.github.io/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Sublime Text 使用技巧3]]></title>
    <link href="http://vra.github.io/2015/06/02/sublime-text-summary-3/"/>
    <id>http://vra.github.io/2015/06/02/sublime-text-summary-3/</id>
    <published>2015-06-02T12:47:10.000Z</published>
    <updated>2017-01-08T09:23:44.734Z</updated>
    <content type="html"><![CDATA[<h2 id="主题管理插件Themr">主题管理插件Themr</h2><p>这个插件用命令的形式来管理、设置主题Theme，省去了点击按钮的繁琐操作，对喜爱简单操作的用户来说很有用。<br>安装方式：<strong>Package Control Install</strong>-&gt;输入<strong>Themr</strong>安装即可。</p>
<a id="more"></a>
<h2 id="文件和文件夹的不显示">文件和文件夹的不显示</h2><p>之前提到过，Sublime Text可以打开一个文件夹，并将文件夹中所有内容列出到左侧。我们可以进行设置，使一些文件夹和文件不显示出来。具体做法如下：</p>
<ol>
<li><p>先将文件夹保存为<code>sublime-project</code>: <strong>Project-&gt;Save Project As…</strong>，选择保存位置</p>
</li>
<li><p>重新打开保存的sublime-project文件，就弹出了文件列表和一个配置文件，在配置文件里面添加下面语句：</p>
</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="string">"folders"</span>:</span><br><span class="line">	[</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="comment">//added part</span></span><br><span class="line">			<span class="string">"folder_exclude_patterns"</span>:[<span class="string">"figures"</span>],</span><br><span class="line">			<span class="string">"file_exclude_patterns"</span>:[<span class="string">"*.md"</span>]</span><br><span class="line">		&#125;</span><br><span class="line">	]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>保存后，可以看到，文件列表里面<code>figures</code>文件夹已经不见了，所有<code>md</code>格式的文件也步显示了。<br>注意：设置了不显示后，使用<strong>Ctrl-P</strong>命令搜索内容的时候，被屏蔽的文件夹和文件中的内容是搜不到的。</p>
<p>上面这种方法只能设置当前打开的项目的情况，如果要对所有的工程都屏蔽某一类文件，则可以在<strong>Preferences-&gt;Settings-User</strong>中添加上面两条语句，则对所有项目都适用。</p>
<h2 id="快速书写CSS代码的插件hayaku">快速书写CSS代码的插件hayaku</h2><p>这个插件可以帮助你快速地书写css代码，可以使用简单的几个字母组合就能写出很长的css格式代码，如<code>ml10</code>会被解析成<code>margin-left:10px;</code>。<br>安装方法：搜索<strong>hayaku</strong>进行安装即可。</p>
<h2 id="Sublime_Text_3中的代码提示SublimeLinter，注意与Sublime_Text_2中很不相同">Sublime Text 3中的代码提示SublimeLinter，注意与Sublime Text 2中很不相同</h2><p>Sublime Text 3中的代码提示插件<strong>SublimeLinter</strong>改进较大，安装方式也不一样，安装<strong>SublimeLinter</strong>后单独安装针对每一种语言的<code>linter</code>，可以先安装<strong>SublimeLinter</strong>，然后看<code>Readme</code>文档查看如何安装剩余的部分。<br>关掉代码提示可以在<code>Ctrl-Shift-P</code>搜<strong>SublimeLinter:Toggle</strong> 来设置开启或关闭</p>
<h2 id="颜色提示插件Color_Hightlight">颜色提示插件Color Hightlight</h2><p>在编写代码时，颜色的标记常常和颜色对应不上，给出一个颜色标记<code>#955278</code>，很难一下子想象到对应的是什么颜色。于是，<strong>Color Hightlight</strong>出现了。安装了这个插件之后，只要点击代码中的颜色标记，就会在该标记上显示对应的颜色，确实很有用的～<br>安装：搜索<strong>Color Hightlight</strong>安装即可。</p>
<h2 id="取色器插件ColorPicker">取色器插件ColorPicker</h2><p>这个插件可以获取颜色，然后直接在代码中使用。启动插件的快捷键：<code>Ctrl-Shift-c</code>。面板出来后一看就知道咋用了。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="主题管理插件Themr">主题管理插件Themr</h2><p>这个插件用命令的形式来管理、设置主题Theme，省去了点击按钮的繁琐操作，对喜爱简单操作的用户来说很有用。<br>安装方式：<strong>Package Control Install</strong>-&gt;输入<strong>Themr</strong>安装即可。</p>]]>
    
    </summary>
    
      <category term="Sublime Text" scheme="http://vra.github.io/tags/Sublime-Text/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[博客迁移记录]]></title>
    <link href="http://vra.github.io/2015/06/02/blog-transfer-record/"/>
    <id>http://vra.github.io/2015/06/02/blog-transfer-record/</id>
    <published>2015-06-02T12:27:40.000Z</published>
    <updated>2017-01-08T09:23:44.718Z</updated>
    <content type="html"><![CDATA[<p>前几天，我把原先部署在科大lug服务器上的wordpress<a href="http://vra.blog.ustc.edu.cn/" target="_blank" rel="external">博客</a>迁移到了github上，也就是现在这个网站。</p>
<h2 id="2015-7-31日更新">2015-7-31日更新</h2><p>前一段时间，我的Ubuntu系统突然出现问题，开机进入系统后，只显示桌面，侧边烂和其他内容都不显示，重启好几次也没用，这时候啥都干不了了，系统里面的内容也没法备份。没办法我就重装了个Debian系统，而原先系统的内容全部丢失T_T，连同我的保存在本地的markdown格式的博客内容。  </p>
<p>我原本以为github上也许有md格式的博客内容，然而并没有，只有转化为<code>html</code>格式的内容。所以我只能从html文件里面手动恢复出md格式的文件，然后再贴到网上，这几乎花费了我一整天的时间，所以以后要吸取教训，要么进行备份，要么采用多站共同部署的方法（如在gitcafe上同样部署一份博客内容），保证内容不丢失。</p>
<a id="more"></a>
<h2 id="首先推广下我们学校的LUG服务,:)">首先推广下我们学校的LUG服务,:)</h2><p>中科大LUG协会主页：<a href="http://lug.ustc.edu.cn" target="_blank" rel="external">http://lug.ustc.edu.cn</a>由校园里技术实力很强的一些学生和已经离校工作或去别的地方深造的技术大牛组成，为本校学生和外校人员提供了许多很有用的服务，包括<a href="http://mirrors.ustc.edu.cn/" target="_blank" rel="external">开源软件镜像网站mirrors</a>,Linux 虚拟主机<a href="http://freeshell.ustc.edu.cn" target="_blank" rel="external">freeshell</a>，<a href="https://blog.ustc.edu.cn/" target="_blank" rel="external">科大博客</a>，代码托管站点<a href="https://gitlab.lug.ustc.edu.cn" target="_blank" rel="external">gitlab</a>等等。这些服务的主机主要是靠学校提供或实验室捐赠，大多都比较老旧，而且维护人员都是边进行学业边维护的。在如此艰难的情境下还是为我们提供了高质量的服务，真的很感谢USTC LUG的同学们！</p>
<h2 id="wordpress博客的一些问题">wordpress博客的一些问题</h2><p>我在使用科大博客的时候，发现了一些wordpress存在的问题，而且由于我对网站开发这方面不是很懂，所以没法解决，每次都用很笨的办法搞定，很浪费时间，有的时候也没法可想。我遇到的问题有下面几个</p>
<ol>
<li>HTML转义字符的问题<br>在博客中的代码段的标签符号，如&lt;，&gt;，&amp;都会被转义为相应的标记。被这个问题困扰了很久，但都没找到好的解决方法。</li>
<li>使用markdown插件编辑代码时，<code>`` 标记转化为代码的时候总是会多出来一个</code> ，代码段看起来很丑。</li>
<li>wordpress插件和主题经常需要更新，比较烦。。。</li>
</ol>
<p>wordpress是动态博客框架，而我的博客内容大多是一些平时学习总结，做个静态的博客即可，既加快了访问速度，又省去了wordpress庞大的框架。</p>
<h2 id="结缘Hexo">结缘Hexo</h2><p>在这学期的LuG小聚活动中，有一次有一个同学讲了关于静态博客Hexo的内容，发现Hexo优点多多，框架轻巧，部署简单，界面美观，而且有插件能方便地迁入或迁出。于是渐渐地，心向往之。</p>
<h2 id="迁移">迁移</h2><p>前几天我打算写点关于Sublime Text编辑器使用总结的博客，在wordpress里面写的时候，上面提到的问题又困扰我来了，没办法，我试着在网上找了些在github上部署hexo的资料，尝试这把博客内容都迁移到github上。</p>
<ol>
<li>将Hexo部署到github上</li>
<li>通过插件将wordpress内容迁移过来</li>
<li>调整迁移过程中出现问题的博客内容</li>
<li>换了一个pacman的主题</li>
<li>又换了个jacman的主题，由心灵手巧、多才多艺的女票设计了博客的logo</li>
</ol>
<p>于是，这个网站就建好了～</p>
<h2 id="hexo的问题">hexo的问题</h2><p>Hexo的博客内容都是以markdown文件保存在本地，所以就没法在别的系统或环境下修改博客了。我尝试了修改github.io的respository内容，但都会在下次在本地部署时被覆盖掉，所以对于使用双系统的情况，就没法在多处修改博客内容了。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>前几天，我把原先部署在科大lug服务器上的wordpress<a href="http://vra.blog.ustc.edu.cn/">博客</a>迁移到了github上，也就是现在这个网站。</p>
<h2 id="2015-7-31日更新">2015-7-31日更新</h2><p>前一段时间，我的Ubuntu系统突然出现问题，开机进入系统后，只显示桌面，侧边烂和其他内容都不显示，重启好几次也没用，这时候啥都干不了了，系统里面的内容也没法备份。没办法我就重装了个Debian系统，而原先系统的内容全部丢失T_T，连同我的保存在本地的markdown格式的博客内容。  </p>
<p>我原本以为github上也许有md格式的博客内容，然而并没有，只有转化为<code>html</code>格式的内容。所以我只能从html文件里面手动恢复出md格式的文件，然后再贴到网上，这几乎花费了我一整天的时间，所以以后要吸取教训，要么进行备份，要么采用多站共同部署的方法（如在gitcafe上同样部署一份博客内容），保证内容不丢失。</p>]]>
    
    </summary>
    
      <category term="博客备忘" scheme="http://vra.github.io/tags/%E5%8D%9A%E5%AE%A2%E5%A4%87%E5%BF%98/"/>
    
  </entry>
  
</feed>